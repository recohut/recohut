{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8HLW6JYZFKW"
      },
      "outputs": [],
      "source": [
        "# default_exp datasets.mts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zWMoTD0ZFKZ"
      },
      "source": [
        "# MTS Dataset\n",
        "> data from the MTS Kion application on user interactions with content for a period of 6 months.\n",
        "\n",
        "The presented dataset contains data on users and objects (series / movies), as well as on their interactions (content viewing by the user) from the Kion online cinema. Content view data collected for ~6 months, from 2021-03-13 to 2021-08-22 inclusive, and diluted with random noise. User and content IDs are anonymised.\n",
        "\n",
        "### users.csv\n",
        "This file contains information about users:\n",
        "- user_id - User ID\n",
        "- age - user's age group, string like \"M_N\".\n",
        " - 18_24 - from 18 to 24 years old inclusive\n",
        " - 25_34 - from 25 to 34 years old inclusive\n",
        " - 35_44 - from 35 to 44 years old inclusive\n",
        " - 45_54 - from 45 to 54 years old inclusive\n",
        " - 55_64 - from 55 to 64 years old inclusive\n",
        " - 65_inf - from 65 and older\n",
        "- sex - user gender\n",
        " - M - man\n",
        " - F - woman\n",
        "- income - user's income, string like \"M_N\n",
        " - income_0_20\n",
        " - income_20_40\n",
        " - income_40_60\n",
        " - income_60_90  \n",
        " - income_90_150\n",
        " - income_150_inf\n",
        "- kids_flg - flag \"presence of a child\n",
        "\n",
        "### items.csv\n",
        "This file contains information about objects (movies/series):\n",
        "- item_id - Content ID\n",
        "- content_type - Type of content (movie, series)\n",
        "- title - Title in Russian\n",
        "- title_orig - original name\n",
        "- genres - Genres from source (online movie theaters)\n",
        "- countries - country\n",
        "- for_kids - flag \"content for children\"\n",
        "- age_rating - age rating\n",
        "- studios - studios\n",
        "- directors - directors\n",
        "- actors - actors\n",
        "- keywords - keywords\n",
        "- description - description\n",
        "\n",
        "### interactions.csv\n",
        "This file contains information about user interactions with content:\n",
        "- user_id - User ID\n",
        "- item_id - Content ID\n",
        "- last_watch_dt - Date last viewed\n",
        "- total_dur - The total duration of all views of this content in seconds\n",
        "- content_type - Type of content (movie, series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8T-xLzCZFKd"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Ahqlf9ZFKe"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "from typing import Any, Iterable, List, Optional, Tuple, Union, Callable\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from recohut.utils.common_utils import *\n",
        "from recohut.datasets.bases.interactions import InteractionsDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bFipjS4ZFKg"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class MTSDataset(InteractionsDataset):\n",
        "    url_users = \"https://github.com/RecoHut-Datasets/mts_kion/raw/v1/users.parquet.snappy\"\n",
        "    url_items = \"https://github.com/RecoHut-Datasets/mts_kion/raw/v1/items.parquet.snappy\"\n",
        "    url_inter = \"https://github.com/RecoHut-Datasets/mts_kion/raw/v1/interactions.parquet.snappy\"\n",
        "\n",
        "    def __init__(self, sample_frac=1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sample_frac = sample_frac\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['users.parquet.snappy',\n",
        "                'items.parquet.snappy',\n",
        "                'interactions.parquet.snappy']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['users_processed.csv',\n",
        "                'items_processed.csv',\n",
        "                'interactions_processed.csv',\n",
        "                'item_stats.csv']\n",
        "\n",
        "    def download(self):\n",
        "        _ = download_url(self.url_users, self.raw_dir)\n",
        "        _ = download_url(self.url_items, self.raw_dir)\n",
        "        _ = download_url(self.url_inter, self.raw_dir)\n",
        "\n",
        "    def load_users_df(self):\n",
        "        df = pd.read_parquet(self.raw_paths[0])\n",
        "        return df\n",
        "\n",
        "    def load_items_df(self):\n",
        "        df = pd.read_parquet(self.raw_paths[1])\n",
        "        return df\n",
        "\n",
        "    def load_ratings_df(self):\n",
        "        df = pd.read_parquet(self.raw_paths[2])\n",
        "        df = df.sample(frac=sample_frac)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def add_user_stats(interactions_df, users_df, split_name=''):\n",
        "        \"\"\"\n",
        "        Computes user watches stats for particular interactions date split\n",
        "        and adds them to users dataframe with specific name\n",
        "        \"\"\"\n",
        "        user_watch_count_all = interactions_df[\n",
        "            interactions_df['total_dur'] > 300].groupby(by='user_id')['item_id'].count()\n",
        "        max_date_df = interactions_df['last_watch_dt'].max()\n",
        "        user_watch_count_last_14 = interactions_df[\n",
        "            (interactions_df['total_dur'] > 300) &\n",
        "            (interactions_df['last_watch_dt'] >= (max_date_df - pd.Timedelta(days=14)))\n",
        "            ].groupby(by='user_id')['item_id'].count()\n",
        "        user_watch_count_all.name = split_name + \"user_watch_cnt_all\"\n",
        "        user_watch_count_last_14.name = split_name + \"user_watch_cnt_last_14\"\n",
        "        user_watches = pd.DataFrame(user_watch_count_all).join(user_watch_count_last_14,\n",
        "                                                            how='outer')\n",
        "        user_watches.fillna(0, inplace=True)\n",
        "        cols = user_watches.columns\n",
        "        user_watches[cols] = user_watches[cols].astype('int64')\n",
        "        users_df = users_df.join(user_watches, on='user_id', how='outer')\n",
        "        users_df[cols] = users_df[cols].fillna(0)\n",
        "        users_df['age'] = users_df['age'].fillna('age_unknown')\n",
        "        users_df['income'] = users_df['income'].fillna('income_unknown')\n",
        "        users_df['sex'] = users_df['sex'].fillna('sex_unknown')\n",
        "        users_df['kids_flg'] = users_df['kids_flg'].fillna(False)\n",
        "        return users_df\n",
        "\n",
        "    @staticmethod\n",
        "    def add_item_watches_stats(interactions_df, items_df, item_stats):\n",
        "        \"\"\"\n",
        "        Computes item watches stats for particular interactions date split\n",
        "        and adds them to item_stats dataframe\n",
        "        \"\"\"\n",
        "\n",
        "        def smooth(series, window_size, smoothing_func):\n",
        "            \"\"\"Computes smoothed interactions statistics for item\"\"\"\n",
        "            series = np.array(series)\n",
        "            ext = np.r_[2 * series[0] - series[window_size - 1::-1],\n",
        "                        series,\n",
        "                        2 * series[-1] - series[-1:-window_size:-1]]\n",
        "            weights = smoothing_func(window_size)\n",
        "            smoothed = np.convolve(weights / weights.sum(), ext, mode='same')\n",
        "            return smoothed[window_size:-window_size + 1]\n",
        "\n",
        "        def trend_slope(series, window_size=7, smoothing_func=np.hamming):\n",
        "            \"\"\"Computes trend slope for item interactions\"\"\"\n",
        "            smoothed = smooth(series, window_size, smoothing_func)\n",
        "            return smoothed[-1] - smoothed[-2]\n",
        "\n",
        "        keep = item_stats.columns\n",
        "        max_date = interactions_df['last_watch_dt'].max()\n",
        "        cols = list(range(7))\n",
        "        for col in cols:\n",
        "            watches = interactions_df[\n",
        "                interactions_df['last_watch_dt'] ==\n",
        "                max_date - pd.Timedelta(days=6 - col)]\n",
        "            item_stats = item_stats.join(\n",
        "                watches.groupby('item_id')['user_id'].count(), lsuffix=col)\n",
        "        item_stats.fillna(0, inplace=True)\n",
        "        new_colnames = ['user_id' + str(i) for i in range(1, 7)] + ['user_id']\n",
        "        trend_slope_to_row = lambda row: trend_slope(row[new_colnames],\n",
        "                                                    window_size=7)\n",
        "        item_stats['trend_slope'] = item_stats.apply(trend_slope_to_row,\n",
        "                                                    axis=1)\n",
        "        item_stats['watched_in_7_days'] = item_stats[new_colnames].apply(\n",
        "            sum, axis=1)\n",
        "        item_stats['watch_ts_quantile_95'] = 0\n",
        "        item_stats['watch_ts_median'] = 0\n",
        "        item_stats['watch_ts_std'] = 0\n",
        "        for item_id in item_stats.index:\n",
        "            watches = interactions_df[interactions_df['item_id'] == item_id]\n",
        "            day_of_year = watches['last_watch_dt'].apply(\n",
        "                lambda x: x.dayofyear).astype(np.int64)\n",
        "            item_stats.loc[item_id, 'watch_ts_quantile_95'] = \\\n",
        "                day_of_year.quantile(q=0.95, interpolation='nearest')\n",
        "            item_stats.loc[item_id, 'watch_ts_median'] = \\\n",
        "                day_of_year.quantile(q=0.5, interpolation='nearest')\n",
        "            item_stats.loc[item_id, 'watch_ts_std'] = day_of_year.std()\n",
        "        item_stats['watch_ts_quantile_95_diff'] = \\\n",
        "            max_date.dayofyear - item_stats['watch_ts_quantile_95']\n",
        "        item_stats['watch_ts_median_diff'] = max_date.dayofyear - \\\n",
        "                                            item_stats['watch_ts_median']\n",
        "        watched_all_time = interactions_df.groupby('item_id')['user_id'].count()\n",
        "        watched_all_time.name = 'watched_in_all_time'\n",
        "        item_stats = item_stats.join(watched_all_time, on='item_id', how='left')\n",
        "        item_stats.fillna(0, inplace=True)\n",
        "        added_cols = ['trend_slope',\n",
        "                    'watched_in_7_days',\n",
        "                    'watch_ts_quantile_95_diff',\n",
        "                    'watch_ts_median_diff',\n",
        "                    'watch_ts_std',\n",
        "                    'watched_in_all_time']\n",
        "        return item_stats[list(keep) + added_cols]\n",
        "\n",
        "    @staticmethod\n",
        "    def add_age_stats(interactions, item_stats, users_df):\n",
        "        \"\"\"\n",
        "        Computes watchers age stats for items with particular interactions \n",
        "        date split and adds them to item_stats dataframe\n",
        "        \"\"\"\n",
        "        item_stats.reset_index(inplace=True)\n",
        "        interactions = interactions.set_index('user_id').join(\n",
        "            users_df[['user_id', 'sex', 'age', 'income']].set_index('user_id'))\n",
        "        interactions.reset_index(inplace=True)\n",
        "        interactions['age_overall'] = interactions['age'].replace(\n",
        "            to_replace={'age_18_24': 'less_35',\n",
        "                        'age_25_34': 'less_35',\n",
        "                        'age_35_44': 'over_35',\n",
        "                        'age_45_54': 'over_35',\n",
        "                        'age_65_inf': 'over_35',\n",
        "                        'age_55_64': 'over_35'})\n",
        "        age_stats = interactions.groupby('item_id')['age_overall'] \\\n",
        "            .value_counts(normalize=True)\n",
        "        age_stats = pd.DataFrame(age_stats)\n",
        "        age_stats.columns = ['value']\n",
        "        age_stats.reset_index(inplace=True)\n",
        "        age_stats.columns = ['item_id', 'age_overall', 'value']\n",
        "        age_stats = age_stats.pivot(\n",
        "            index='item_id', columns='age_overall', values='value').drop(\n",
        "            'age_unknown', axis=1)\n",
        "        age_stats.fillna(0, inplace=True)\n",
        "        item_stats = item_stats.set_index('item_id').join(age_stats)\n",
        "        item_stats[['less_35', 'over_35']] = item_stats[['less_35', 'over_35']] \\\n",
        "            .fillna(0)\n",
        "        item_stats.rename(columns={'less_35': 'younger_35_fraction',\n",
        "                                'over_35': 'older_35_fraction'},\n",
        "                        inplace=True)\n",
        "        return item_stats\n",
        "\n",
        "    @staticmethod\n",
        "    def add_sex_stats(interactions, item_stats, users_df):\n",
        "        \"\"\"\n",
        "        Computes watchers sex stats for items with particular interactions date split\n",
        "        and adds them to item_stats dataframe\n",
        "        \"\"\"\n",
        "        item_stats.reset_index(inplace=True)\n",
        "        interactions = interactions.set_index('user_id') \\\n",
        "            .join(users_df[['user_id', 'sex', 'age', 'income']]\n",
        "                .set_index('user_id'))\n",
        "        interactions.reset_index(inplace=True)\n",
        "        sex_stats = interactions.groupby('item_id')['sex'] \\\n",
        "            .value_counts(normalize=True)\n",
        "        sex_stats = pd.DataFrame(sex_stats)\n",
        "        sex_stats.columns = ['value']\n",
        "        sex_stats.reset_index(inplace=True)\n",
        "        sex_stats.columns = ['item_id', 'sex', 'value']\n",
        "        sex_stats = sex_stats.pivot(index='item_id',\n",
        "                                    columns='sex',\n",
        "                                    values='value').drop('sex_unknown', axis=1)\n",
        "        sex_stats.fillna(0, inplace=True)\n",
        "        item_stats = item_stats.set_index('item_id').join(sex_stats)\n",
        "        item_stats[['F', 'M']] = item_stats[['F', 'M']].fillna(0)\n",
        "        item_stats.rename(columns={'F': 'female_watchers_fraction',\n",
        "                                'M': 'male_watchers_fraction'},\n",
        "                        inplace=True)\n",
        "        return item_stats\n",
        "\n",
        "    @staticmethod\n",
        "    def get_coo_matrix(df,\n",
        "                    user_col='user_id',\n",
        "                    item_col='item_id',\n",
        "                    weight_col=None,\n",
        "                    users_mapping={},\n",
        "                    items_mapping={}):\n",
        "        if weight_col is None:\n",
        "            weights = np.ones(len(df), dtype=np.float32)\n",
        "        else:\n",
        "            weights = df[weight_col].astype(np.float32)\n",
        "\n",
        "        interaction_matrix = sp.coo_matrix((\n",
        "            weights,\n",
        "            (\n",
        "                df[user_col].map(users_mapping.get),\n",
        "                df[item_col].map(items_mapping.get)\n",
        "            )\n",
        "        ))\n",
        "        return interaction_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def create_mapping():\n",
        "        # Creating items and users mapping\n",
        "        users_inv_mapping = dict(enumerate(df['user_id'].unique()))\n",
        "        users_mapping = {v: k for k, v in users_inv_mapping.items()}\n",
        "        items_inv_mapping = dict(enumerate(df['item_id'].unique()))\n",
        "        items_mapping = {v: k for k, v in items_inv_mapping.items()}\n",
        "\n",
        "    def process(self):\n",
        "        # load data\n",
        "        print('Loading data')\n",
        "        users_df = self.load_users_df()\n",
        "        items_df = self.load_items_df()\n",
        "        interactions_df = self.load_ratings_df()\n",
        "\n",
        "        # users info preprocessing\n",
        "        print('Processing users info')\n",
        "        users_df['age'] = users_df['age'].fillna('age_unknown')\n",
        "        users_df['age'] = users_df['age'].astype('category')\n",
        "        users_df['income'] = users_df['income'].fillna('income_unknown')\n",
        "        users_df['income'] = users_df['income'].astype('category')\n",
        "        users_df['sex'] = users_df['sex'].fillna('sex_unknown')\n",
        "        users_df.loc[users_df.sex == 'М', 'sex'] = 'M'\n",
        "        users_df.loc[users_df.sex == 'Ж', 'sex'] = 'F'\n",
        "        users_df['sex'] = users_df['sex'].astype('category')\n",
        "        users_df['kids_flg'] = users_df['kids_flg'].astype('bool')\n",
        "\n",
        "        # items info preprocessing\n",
        "        print('Processing items info')\n",
        "        items_df['content_type'] = items_df['content_type'].astype('category')\n",
        "        items_df['title'] = items_df['title'].str.lower()\n",
        "        items_df['title_orig'] = items_df['title_orig'].fillna('None')\n",
        "        items_df.loc[items_df['release_year'] < 1980, 'release_novelty'] = 1\n",
        "        items_df.loc[items_df['release_year'] >= 2020, 'release_novelty'] = 6\n",
        "        novelty = 1\n",
        "        for i in range(1980, 2020, 10):\n",
        "            novelty += 1\n",
        "            items_df.loc[(items_df['release_year'] >= i) &\n",
        "                        (items_df['release_year'] < i + 10), 'release_novelty'] = novelty\n",
        "        items_df = items_df.drop(columns=['release_year'])\n",
        "        items_df['for_kids'] = items_df['for_kids'].fillna(0)\n",
        "        items_df['for_kids'] = items_df['for_kids'].astype('bool')\n",
        "        items_df.loc[items_df.age_rating.isna(), 'age_rating'] = 0\n",
        "        items_df['age_rating'] = items_df['age_rating'].astype('category')\n",
        "        items_df['genres_list'] = items_df['genres'].apply(lambda x: x.split(', '))\n",
        "        num_genres = pd.Series(np.hstack(items_df['genres_list'].values)).value_counts()\n",
        "        items_df['genres_min'] = items_df['genres_list'].apply(\n",
        "            lambda x: min([num_genres[el] for el in x]))\n",
        "        items_df['genres_max'] = items_df['genres_list'].apply(\n",
        "            lambda x: max([num_genres[el] for el in x]))\n",
        "        items_df['genres_med'] = items_df['genres_list'].apply(\n",
        "            lambda x: (np.median([num_genres[el] for el in x])))\n",
        "        items_df['countries'].fillna('None', inplace=True)\n",
        "        items_df['countries'] = items_df['countries'].str.lower()\n",
        "        items_df['countries_list'] = items_df['countries'].apply(\n",
        "            lambda x: x.split(', ') if ', ' in x else [x])\n",
        "        num_countries = pd.Series(np.hstack(items_df['countries_list'].values)).value_counts()\n",
        "        items_df['countries_max'] = items_df['countries_list'].apply(\n",
        "            lambda x: max([num_countries[el] for el in x]))\n",
        "        items_df['studios'].fillna('None', inplace=True)\n",
        "        items_df['studios'] = items_df['studios'].str.lower()\n",
        "        items_df['studios_list'] = items_df['studios'].apply(\n",
        "            lambda x: x.split(', ') if ', ' in x else [x])\n",
        "        num_studios = pd.Series(np.hstack(items_df['studios_list'].values)).value_counts()\n",
        "        items_df['studios_max'] = items_df['studios_list'].apply(\n",
        "            lambda x: max([num_studios[el] for el in x]))\n",
        "        items_df.drop(['countries_list', 'genres_list', 'studios_list'],\n",
        "                    axis=1, inplace=True)\n",
        "        \n",
        "        # interactions preprocessing\n",
        "        print('Processing interactions')\n",
        "        interactions_df['watched_pct'] = interactions_df['watched_pct'].astype(\n",
        "            pd.Int8Dtype())\n",
        "        interactions_df['watched_pct'] = interactions_df['watched_pct'].fillna(0)\n",
        "        interactions_df['last_watch_dt'] = pd.to_datetime(\n",
        "            interactions_df['last_watch_dt'])\n",
        "        interactions_df.sort_values(by='last_watch_dt', inplace=True)\n",
        "        \n",
        "        # user stats feature engineering\n",
        "        print('Processing users stats')\n",
        "        max_date = interactions_df['last_watch_dt'].max()\n",
        "        boosting_split_date = max_date - pd.Timedelta(days=14)\n",
        "        interactions_boost = interactions_df[\n",
        "            interactions_df['last_watch_dt'] <= boosting_split_date]\n",
        "        users_df = self.add_user_stats(interactions_boost, users_df, split_name='boost_')\n",
        "        users_df = self.add_user_stats(interactions_df, users_df, split_name='')\n",
        "\n",
        "        # Item stats\n",
        "        print('Processing items stats')\n",
        "        item_stats = items_df[['item_id']]\n",
        "        item_stats = item_stats.set_index('item_id')\n",
        "        item_stats = self.add_item_watches_stats(interactions_boost, items_df, item_stats)\n",
        "        item_stats.fillna(0, inplace=True)\n",
        "        item_stats = self.add_sex_stats(interactions_boost, item_stats, users_df)\n",
        "        item_stats = self.add_age_stats(interactions_boost, item_stats, users_df)\n",
        "\n",
        "        # Saving preprocessed files\n",
        "        users_df.to_csv(self.processed_paths[0], index=False)\n",
        "        items_df.to_csv(self.processed_paths[1], index=False)\n",
        "        interactions_df.to_csv(self.processed_paths[2], index=False)\n",
        "        item_stats.to_csv(self.processed_paths[3], index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r5wpyxkZFKu"
      },
      "source": [
        "Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNRPssaMZFKz"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "!apt-get -qq install tree\n",
        "!pip install -q watermark\n",
        "!pip install -q pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o93FcwcGZFK0",
        "outputId": "3616d07c-f450-4baa-b0ab-145a1b66665d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/RecoHut-Datasets/mts_kion/raw/v1/users.parquet.snappy\n",
            "Downloading https://github.com/RecoHut-Datasets/mts_kion/raw/v1/items.parquet.snappy\n",
            "Downloading https://github.com/RecoHut-Datasets/mts_kion/raw/v1/interactions.parquet.snappy\n",
            "Processing...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data\n",
            "Processing users info\n",
            "Processing items info\n",
            "Processing interactions\n",
            "Processing users stats\n",
            "Processing items stats\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "ds = MTSDataset(data_dir='/content/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFAUa3WUZFK3",
        "outputId": "bc8c4f88-2b1d-4d37-8f80-e0e6405350d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34m./data\u001b[00m\n",
            "├── [250M]  \u001b[01;34mprocessed\u001b[00m\n",
            "│   ├── [161M]  interactions_processed.csv\n",
            "│   ├── [ 31M]  items_processed.csv\n",
            "│   ├── [1.5M]  item_stats_for_boost_train.csv\n",
            "│   ├── [1.5M]  item_stats_for_submit.csv\n",
            "│   └── [ 55M]  users_processed.csv\n",
            "└── [ 77M]  \u001b[01;34mraw\u001b[00m\n",
            "    ├── [ 56M]  interactions.parquet.snappy\n",
            "    ├── [ 15M]  items.parquet.snappy\n",
            "    └── [5.1M]  users.parquet.snappy\n",
            "\n",
            " 327M used in 2 directories, 8 files\n"
          ]
        }
      ],
      "source": [
        "!tree --du -h -C ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF_eD4t9ZFK4"
      },
      "source": [
        "> **References**\n",
        "> - https://ods.ai/tracks/recsys-course2021/competitions/competition-recsys-21\n",
        "> - https://github.com/blondered/ods_MTS_RecSys_Challenge_solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gs4ybL7ZFK6",
        "outputId": "785735fa-4ddd-4f23-8b2d-55f5da001c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Author: Sparsh A.\n",
            "\n",
            "Last updated: 2022-01-14 10:32:26\n",
            "\n",
            "recohut: 0.0.11\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 5.4.144+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "IPython: 5.5.0\n",
            "pandas : 1.1.5\n",
            "numpy  : 1.19.5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "datasets.mts.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}