{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm7mvX3bPJ5W"
      },
      "outputs": [],
      "source": [
        "# default_exp models.bases.sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_rOf1fmPJ5g"
      },
      "source": [
        "# Sequential Base Model\n",
        "> Implementation of sequential base models in Pytorch Lightning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OreNWaLMPJ5l"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rRa8lX6PJ5n"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "from typing import Any, Iterable, List, Optional, Tuple, Union, Callable\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from pytorch_lightning import LightningModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usBFLMB5PJ5p"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class SequentialModel(LightningModule):\n",
        "    def __init__(self,\n",
        "                 optimizer='adamw',\n",
        "                 learning_rate = 0.003,\n",
        "                 cap = 0,\n",
        "                 mask = 1,\n",
        "                 dropout = 0.4,\n",
        "                 vocab_size = 1000,\n",
        "                 channels = 128,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.cap = cap\n",
        "        self.mask = mask\n",
        "        self.dropout = dropout\n",
        "        self.vocab_size = vocab_size\n",
        "        self.channels = channels\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_accuracy(y_pred: torch.Tensor, y_true: torch.Tensor, mask: torch.Tensor):\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        y_true = torch.masked_select(y_true, mask)\n",
        "        predicted = torch.masked_select(predicted, mask)\n",
        "        acc = (y_true == predicted).double().mean()\n",
        "        return acc\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_ce(y_pred, y_true, mask):\n",
        "        loss = F.cross_entropy(y_pred, y_true, reduction=\"none\")\n",
        "        loss = loss * mask\n",
        "        return loss.sum() / (mask.sum() + 1e-8)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src_items, y_true = batch\n",
        "        y_pred = self(src_items)\n",
        "        y_pred = y_pred.view(-1, y_pred.size(2))\n",
        "        y_true = y_true.view(-1)\n",
        "        src_items = src_items.view(-1)\n",
        "        mask = src_items == self.mask\n",
        "        loss = self.masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        accuracy = self.masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_accuracy\", accuracy)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src_items, y_true = batch\n",
        "        y_pred = self(src_items)\n",
        "        y_pred = y_pred.view(-1, y_pred.size(2))\n",
        "        y_true = y_true.view(-1)\n",
        "        src_items = src_items.view(-1)\n",
        "        mask = src_items == self.mask\n",
        "        loss = self.masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        accuracy = self.masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        self.log(\"valid_loss\", loss)\n",
        "        self.log(\"valid_accuracy\", accuracy)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        src_items, y_true = batch\n",
        "        y_pred = self(src_items)\n",
        "        y_pred = y_pred.view(-1, y_pred.size(2))\n",
        "        y_true = y_true.view(-1)\n",
        "        src_items = src_items.view(-1)\n",
        "        mask = src_items == self.mask\n",
        "        loss = self.masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        accuracy = self.masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_accuracy\", accuracy)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, patience=10, factor=0.1\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": scheduler,\n",
        "            \"monitor\": \"valid_loss\",\n",
        "        }"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "models.bases.sequential.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}