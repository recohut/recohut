{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fycOO2OxKHEF"
      },
      "outputs": [],
      "source": [
        "# default_exp models.layers.encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KypvcFZI64_"
      },
      "source": [
        "# Encoding Layers\n",
        "> Implementation of encoding layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGwuVx5oI65E"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import copy\n",
        "\n",
        "from recohut.models.layers.activation import gelu, swish\n",
        "from recohut.models.layers.attention import SelfAttention, DistSelfAttention, DistMeanSelfAttention"
      ],
      "metadata": {
        "id": "AGKJ4vcbaAFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exporti\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": F.relu, \"swish\": swish}"
      ],
      "metadata": {
        "id": "WDr3CdD4aF5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class Intermediate(nn.Module):\n",
        "    def __init__(self, hidden_size, hidden_act, hidden_dropout_prob):\n",
        "        super().__init__()\n",
        "        self.dense_1 = nn.Linear(hidden_size, hidden_size * 4)\n",
        "        if isinstance(hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = hidden_act\n",
        "\n",
        "        self.dense_2 = nn.Linear(hidden_size * 4, hidden_size)\n",
        "        self.layernorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "        hidden_states = self.dense_1(input_tensor)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "\n",
        "        hidden_states = self.dense_2(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.layernorm(hidden_states + input_tensor)\n",
        "\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "brONaXI1Z_c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "hidden_act = 'swish'\n",
        "hidden_dropout_prob = 0.5\n",
        "\n",
        "layer = Intermediate(hidden_size, hidden_act, hidden_dropout_prob)\n",
        "\n",
        "input_tensor = torch.rand(4,4)\n",
        "\n",
        "output = layer.forward(input_tensor)\n",
        "\n",
        "test_eq(output.shape.numel(), 16)\n",
        "test_eq(output.shape, [4,4])"
      ],
      "metadata": {
        "id": "2eUaCcP1asbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class DistIntermediate(nn.Module):\n",
        "    def __init__(self, hidden_size, hidden_dropout_prob):\n",
        "        super().__init__()\n",
        "        self.dense_1 = nn.Linear(hidden_size, hidden_size * 4)\n",
        "        self.intermediate_act_fn = nn.ELU()\n",
        "\n",
        "        self.dense_2 = nn.Linear(hidden_size * 4, hidden_size)\n",
        "        self.layernorm = nn.LayerNorm(hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "\n",
        "        hidden_states = self.dense_1(input_tensor)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "\n",
        "        hidden_states = self.dense_2(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.layernorm(hidden_states + input_tensor)\n",
        "\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "3xNQTQNrcyoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "hidden_dropout_prob = 0.5\n",
        "\n",
        "layer = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
        "\n",
        "input_tensor = torch.rand(4,4)\n",
        "\n",
        "output = layer.forward(input_tensor)\n",
        "\n",
        "test_eq(output.shape.numel(), 16)\n",
        "test_eq(output.shape, [4,4])"
      ],
      "metadata": {
        "id": "bqvM9cfOc_r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class Layer(nn.Module):\n",
        "    def __init__(self, hidden_size, hidden_act, num_attention_heads, \n",
        "                 hidden_dropout_prob, attention_probs_dropout_prob):\n",
        "        super().__init__()\n",
        "        self.attention = SelfAttention(hidden_size, num_attention_heads, \n",
        "                                       attention_probs_dropout_prob, hidden_dropout_prob)\n",
        "        self.intermediate = Intermediate(hidden_size, hidden_act, hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output, attention_scores = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        return intermediate_output, attention_scores"
      ],
      "metadata": {
        "id": "fLh6Yi59ddyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "hidden_act = 'gelu'\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "\n",
        "layer = Layer(hidden_size, hidden_act, num_attention_heads, \n",
        "              hidden_dropout_prob, attention_probs_dropout_prob)\n",
        "\n",
        "hidden_states = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "hidden_states = torch.round(layer.forward(hidden_states, attention_mask)[0].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(hidden_states.shape.numel(), 32)\n",
        "test_eq(list(hidden_states.shape), [2, 4, 4])\n",
        "\n",
        "attention_probs = torch.round(layer.forward(hidden_states, attention_mask)[1].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(attention_probs.shape.numel(), 64)\n",
        "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
      ],
      "metadata": {
        "id": "M4NEhFKmkVvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class DistLayer(nn.Module):\n",
        "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                 attention_probs_dropout_prob, distance_metric='wasserstein'):\n",
        "        super().__init__()\n",
        "        self.attention = DistSelfAttention(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                                           attention_probs_dropout_prob, distance_metric)\n",
        "        self.mean_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
        "        self.cov_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
        "        self.activation_func = nn.ELU()\n",
        "\n",
        "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask):\n",
        "        mean_attention_output, cov_attention_output, attention_scores = self.attention(mean_hidden_states, cov_hidden_states, attention_mask)\n",
        "        mean_intermediate_output = self.mean_intermediate(mean_attention_output)\n",
        "        cov_intermediate_output = self.activation_func(self.cov_intermediate(cov_attention_output)) + 1\n",
        "        return mean_intermediate_output, cov_intermediate_output, attention_scores"
      ],
      "metadata": {
        "id": "XMGfb6-8luCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "\n",
        "layer = DistLayer(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
        "                  attention_probs_dropout_prob)\n",
        "\n",
        "input_tensor = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
        "\n",
        "mean_hidden_states = torch.round(output[0].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(mean_hidden_states.shape.numel(), 32)\n",
        "test_eq(list(mean_hidden_states.shape), [2, 4, 4])\n",
        "\n",
        "cov_hidden_states = torch.round(output[1].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(cov_hidden_states.shape.numel(), 32)\n",
        "test_eq(list(cov_hidden_states.shape), [2, 4, 4])\n",
        "\n",
        "attention_probs = torch.round(output[2].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(attention_probs.shape.numel(), 64)\n",
        "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
      ],
      "metadata": {
        "id": "A40ouZ9tlzuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class DistMeanSALayer(nn.Module):\n",
        "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                 attention_probs_dropout_prob):\n",
        "        super().__init__()\n",
        "        self.attention = DistMeanSelfAttention(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                                               attention_probs_dropout_prob)\n",
        "        self.mean_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
        "        self.cov_intermediate = DistIntermediate(hidden_size, hidden_dropout_prob)\n",
        "        self.activation_func = nn.ELU()\n",
        "\n",
        "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask):\n",
        "        mean_attention_output, cov_attention_output, attention_scores = self.attention(mean_hidden_states, cov_hidden_states, attention_mask)\n",
        "        mean_intermediate_output = self.mean_intermediate(mean_attention_output)\n",
        "        cov_intermediate_output = self.activation_func(self.cov_intermediate(cov_attention_output)) + 1\n",
        "        return mean_intermediate_output, cov_intermediate_output, attention_scores"
      ],
      "metadata": {
        "id": "xf7YJjmbmkSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "\n",
        "layer = DistMeanSALayer(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
        "                  attention_probs_dropout_prob)\n",
        "\n",
        "input_tensor = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
        "\n",
        "mean_hidden_states = torch.round(output[0].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(mean_hidden_states.shape.numel(), 32)\n",
        "test_eq(list(mean_hidden_states.shape), [2, 4, 4])\n",
        "\n",
        "cov_hidden_states = torch.round(output[1].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(cov_hidden_states.shape.numel(), 32)\n",
        "test_eq(list(cov_hidden_states.shape), [2, 4, 4])\n",
        "\n",
        "attention_probs = torch.round(output[2].detach()*1e4)/1e4\n",
        "\n",
        "test_eq(attention_probs.shape.numel(), 64)\n",
        "test_eq(list(attention_probs.shape), [2, 2, 4, 4])"
      ],
      "metadata": {
        "id": "8wmGIGYYmprl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class DistSAEncoder(nn.Module):               \n",
        "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                 attention_probs_dropout_prob, num_hidden_layers,\n",
        "                 distance_metric='wasserstein'):\n",
        "        super().__init__()\n",
        "        layer = DistLayer(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                          attention_probs_dropout_prob, distance_metric)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
        "                                    for _ in range(num_hidden_layers)])\n",
        "\n",
        "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            maen_hidden_states, cov_hidden_states, att_scores = layer_module(mean_hidden_states, cov_hidden_states, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
        "        return all_encoder_layers"
      ],
      "metadata": {
        "id": "UMbCERaynF1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "num_hidden_layers = 2\n",
        "\n",
        "layer = DistSAEncoder(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
        "                  attention_probs_dropout_prob, num_hidden_layers)\n",
        "\n",
        "input_tensor = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
        "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
        "\n",
        "expected_shapes = [[2, 4, 4], [2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
        "\n",
        "test_eq(output_shapes, expected_shapes)"
      ],
      "metadata": {
        "id": "YADpPiHQnb7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class DistMeanSAEncoder(nn.Module):\n",
        "    def __init__(self, hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                 attention_probs_dropout_prob, num_hidden_layers):\n",
        "        super().__init__()\n",
        "        layer = DistMeanSALayer(hidden_size, num_attention_heads, hidden_dropout_prob, \n",
        "                 attention_probs_dropout_prob)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
        "                                    for _ in range(num_hidden_layers)])\n",
        "\n",
        "    def forward(self, mean_hidden_states, cov_hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            maen_hidden_states, cov_hidden_states, att_scores = layer_module(mean_hidden_states, cov_hidden_states, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append([mean_hidden_states, cov_hidden_states, att_scores])\n",
        "        return all_encoder_layers"
      ],
      "metadata": {
        "id": "i9S3kcG1qBsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "num_hidden_layers = 2\n",
        "\n",
        "layer = DistMeanSAEncoder(hidden_size, num_attention_heads, hidden_dropout_prob,\n",
        "                          attention_probs_dropout_prob, num_hidden_layers)\n",
        "\n",
        "input_tensor = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "output = layer.forward(input_tensor, input_tensor, attention_mask)\n",
        "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
        "\n",
        "expected_shapes = [[2, 4, 4], [2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
        "\n",
        "test_eq(output_shapes, expected_shapes)"
      ],
      "metadata": {
        "id": "1a0hZ9ysqUp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_size, hidden_act, num_attention_heads, \n",
        "                 hidden_dropout_prob, attention_probs_dropout_prob,\n",
        "                 num_hidden_layers):\n",
        "        super().__init__()\n",
        "        layer = Layer(hidden_size, hidden_act, num_attention_heads, \n",
        "                 hidden_dropout_prob, attention_probs_dropout_prob)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer)\n",
        "                                    for _ in range(num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            hidden_states, attention_scores = layer_module(hidden_states, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append([hidden_states, attention_scores])\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append([hidden_states, attention_scores])\n",
        "        return all_encoder_layers"
      ],
      "metadata": {
        "id": "PNhUyUhMZ8MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 4\n",
        "hidden_act = 'swish'\n",
        "num_attention_heads = 2\n",
        "hidden_dropout_prob = 0.2\n",
        "attention_probs_dropout_prob = 0.2\n",
        "num_hidden_layers = 2\n",
        "\n",
        "layer = Encoder(hidden_size, hidden_act, num_attention_heads, hidden_dropout_prob,\n",
        "                          attention_probs_dropout_prob, num_hidden_layers)\n",
        "\n",
        "input_tensor = torch.rand((2,4,4))\n",
        "attention_mask = torch.rand((4,4))\n",
        "\n",
        "output = layer.forward(input_tensor, attention_mask)\n",
        "output_shapes = [list(x.shape) for x in [j for sub in output for j in sub]]\n",
        "\n",
        "expected_shapes = [[2, 4, 4], [2, 2, 4, 4], [2, 4, 4], [2, 2, 4, 4]]\n",
        "\n",
        "test_eq(output_shapes, expected_shapes)"
      ],
      "metadata": {
        "id": "s3zQJKnrq1TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXwRDjpKI65c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169c0e57-60f2-4a48-9791-85036fa2384f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Sparsh A.\n",
            "\n",
            "Last updated: 2022-01-22 16:49:16\n",
            "\n",
            "recohut: 0.0.11\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 5.4.144+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "torch    : 1.10.0+cu111\n",
            "IPython  : 5.5.0\n",
            "watermark: 2.3.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d -p recohut"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1KypvcFZI64_"
      ],
      "name": "models > layers > encoding",
      "provenance": [],
      "mount_file_id": "1FEZmnoLGIsTsGiK2gi1TsIHLAaWCXF_a",
      "authorship_tag": "ABX9TyPze7FLPU/z4yLuLiyuLpI2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}