{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T722684 | TaNP Cold-start Recommender on LastFM dataset","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM+Uba2awrkA+hdY1ZzIei7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"le6ItuZ9aCvt"},"source":["# TaNP Cold-start Recommender on LastFM dataset"]},{"cell_type":"markdown","metadata":{"id":"x47nzfcCZ8cJ"},"source":["Recent studies seek to address this challenge from the perspective of meta learning, and most of them follow a manner of parameter initialization, where the model parameters can be learned by a few steps of gradient updates. While these gradient-based meta-learning models achieve promising performances to some extent, a fundamental problem of them is how to adapt the global knowledge learned from previous tasks for the recommendations of cold-start users more effectively.\n","\n","TaNP directly maps the observed interactions of each user to a predictive distribution, sidestepping some training issues in gradient-based meta-learning models. More importantly, to balance the trade-off between model capacity and adaptation reliability, TaNP uses a novel task-adaptive mechanism. It enables this model to learn the relevance of different tasks and customize the global knowledge to the task-related decoder parameters for estimating user preferences."]},{"cell_type":"markdown","metadata":{"id":"cRWoUWlraKKb"},"source":["Inspired by the significant improvements of meta learning, the pioneering work of [Vartak et. al.](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46346.pdf) provides a meta-learning strategy to solve cold-start problems. It uses a task-dependent way to generate the varying biases of decision layers for different tasks, but it is prone to underfitting and is not flexible enough to handle various recommendation scenarios. [MeLU](https://arxiv.org/abs/1908.00413) adopts the framework of MAML. Specifically, it divides the model parameters into two groups, i.e., the personalized parameter and the embedding parameter. The personalized parameter is characterized as a fully-connected DNN to estimate user preferences. The embedding parameter is referred as the embeddings of users and items learned from side-information. An inner-outer loop is used to update these two groups of parameters. In the inner loop, the personalized parameter is locally updated via the prediction loss of support set in current task. In the outer loop, these parameters are globally updated according to the prediction loss of query sets in multiple tasks. Through the fashion of local-global update, MeLU can provide a shared initialization for different tasks. The later work [MetaCS](https://www.semanticscholar.org/paper/Meta-Learning-for-User-Cold-Start-Recommendation-Bharadhwaj/f3135b553f592dc42d4202c90739c99486103fc3) is much similar to MeLU, and the main difference is that the local-global update involves all parameters from input embedding to model prediction. To generalize well for different tasks, [MetaHIN](https://www.kdd.org/kdd2020/accepted-papers/view/meta-learning-on-heterogeneous-information-networks-for-cold-start-recommen) and [MAMO](https://arxiv.org/abs/2007.03183) propose different task-specific adaptation strategies. In particular, MetaHIN incorporates heterogeneous information networks (HINs) into MAML to capture rich semantics of meta-paths. MAMO introduces two memory matrices based on user profiles: a feature-specific memory that provides a specific bias term for the shared parameter initialization; a task-specific memory that guides the model for predictions. However, these two gradient-based meta-learning models may still suffer from potential training issues in MAML, and the model-level innovations of them are closely related with side-information, which limits their application scenarios."]},{"cell_type":"markdown","metadata":{"id":"2LroOGYgZ9Zg"},"source":["## Background\n","\n","### Meta Learning in Recommenders\n","\n","Inspired by the huge progress on few-shot learning and meta learning, there emerge some promising works on solving cold-start problems from the perspective of meta learning, where making recommendations for one user is regarded as a single task.\n","\n","In the training phase, they try to derive the global knowledge across different tasks as a strong generalization prior. When a cold-start user comes in the test phase, the personalized recommendation for her/him can be predicted with only a few interacted items are available, but does so by using the global knowledge already learned.\n","\n","Most meta-learning recommenders are built upon the well-known framework of model-agnostic meta learning (MAML), aiming to learn a parameter initialization where a few steps of gradient updates will lead to good performances on the new tasks. A typical assumption here is the recommendations of different users are highly relevant. However, this assumption does not necessarily hold in actual scenarios. When the users exhibit different purchase intentions, the task relevance among them is actually very weak, which makes it problematic to find a shared parameter initialization optimal for all users. As shown in the image below:"]},{"cell_type":"markdown","metadata":{"id":"MHKAnNDj0uDM"},"source":["<p><center><img src='_images/T722684_1.png'></center></p>"]},{"cell_type":"markdown","metadata":{"id":"Kh2GBWwXTSsP"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"ej09KyMmTSo-"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"fRVNWsrtSoad"},"source":["import os\n","import json\n","import math\n","import random\n","import pickle\n","import codecs\n","import re\n","import time\n","import datetime\n","from tqdm.notebook import tqdm\n","from datetime import datetime\n","\n","from random import randint\n","from copy import deepcopy\n","from collections import OrderedDict\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.optim.optimizer import Optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ltEYBEhdWwdF"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"NP_OQPAbWxcC"},"source":["!wget -q --show-progress https://github.com/sparsh-ai/coldstart-recsys/raw/main/data/TaNP/data.zip\n","!unzip data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFr79XRqVTlz"},"source":["### Params"]},{"cell_type":"code","metadata":{"id":"19RU9DZyVXmx"},"source":["import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--data_dir', type=str, default='data/lastfm_20')\n","parser.add_argument('--model_save_dir', type=str, default='save_model_dir')\n","parser.add_argument('--id', type=str, default='1', help='used for save hyper-parameters.')\n","\n","parser.add_argument('--first_embedding_dim', type=int, default=32, help='Embedding dimension for item and user.')\n","parser.add_argument('--second_embedding_dim', type=int, default=16, help='Embedding dimension for item and user.')\n","\n","parser.add_argument('--z1_dim', type=int, default=32, help='The dimension of z1 in latent path.')\n","parser.add_argument('--z2_dim', type=int, default=32, help='The dimension of z2 in latent path.')\n","parser.add_argument('--z_dim', type=int, default=32, help='The dimension of z in latent path.')\n","\n","parser.add_argument('--enc_h1_dim', type=int, default=64, help='The hidden first dimension of encoder.')\n","parser.add_argument('--enc_h2_dim', type=int, default=64, help='The hidden second dimension of encoder.')\n","\n","parser.add_argument('--taskenc_h1_dim', type=int, default=128, help='The hidden first dimension of task encoder.')\n","parser.add_argument('--taskenc_h2_dim', type=int, default=64, help='The hidden second dimension of task encoder.')\n","parser.add_argument('--taskenc_final_dim', type=int, default=64, help='The hidden second dimension of task encoder.')\n","\n","parser.add_argument('--clusters_k', type=int, default=7, help='Cluster numbers of tasks.')\n","parser.add_argument('--temperature', type=float, default=1.0, help='used for student-t distribution.')\n","parser.add_argument('--lambda', type=float, default=0.1, help='used to balance the clustering loss and NP loss.')\n","\n","parser.add_argument('--dec_h1_dim', type=int, default=128, help='The hidden first dimension of encoder.')\n","parser.add_argument('--dec_h2_dim', type=int, default=128, help='The hidden second dimension of encoder.')\n","parser.add_argument('--dec_h3_dim', type=int, default=128, help='The hidden third dimension of encoder.')\n","\n","# # used for movie datasets\n","# parser.add_argument('--num_gender', type=int, default=2, help='User information.')\n","# parser.add_argument('--num_age', type=int, default=7, help='User information.')\n","# parser.add_argument('--num_occupation', type=int, default=21, help='User information.')\n","# parser.add_argument('--num_zipcode', type=int, default=3402, help='User information.')\n","# parser.add_argument('--num_rate', type=int, default=6, help='Item information.')\n","# parser.add_argument('--num_genre', type=int, default=25, help='Item information.')\n","# parser.add_argument('--num_director', type=int, default=2186, help='Item information.')\n","# parser.add_argument('--num_actor', type=int, default=8030, help='Item information.')\n","\n","parser.add_argument('--dropout_rate', type=float, default=0, help='used in encoder and decoder.')\n","parser.add_argument('--lr', type=float, default=1e-4, help='Applies to SGD and Adagrad.')\n","parser.add_argument('--optim', type=str, default='adam', help='sgd, adagrad, adam or adamax.')\n","parser.add_argument('--num_epoch', type=int, default=150)\n","parser.add_argument('--batch_size', type=int, default=32)\n","parser.add_argument('--train_ratio', type=float, default=0.7, help='Warm user ratio for training.')\n","parser.add_argument('--valid_ratio', type=float, default=0.1, help='Cold user ratio for validation.')\n","parser.add_argument('--seed', type=int, default=2020)\n","parser.add_argument('--save', type=int, default=0)\n","parser.add_argument('--use_cuda', type=bool, default=torch.cuda.is_available())\n","parser.add_argument('--cpu', action='store_true', help='Ignore CUDA.')\n","parser.add_argument('--support_size', type=int, default=20)\n","parser.add_argument('--query_size', type=int, default=10)\n","parser.add_argument('--max_len', type=int, default=200, help='The max length of interactions for each user.')\n","parser.add_argument('--context_min', type=int, default=20, help='Minimum size of context range.')\n","args = parser.parse_args(args={})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IP7Eu0gRV4mQ"},"source":["def seed_everything(seed=1023):\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed = args.seed\n","seed_everything(seed)\n","\n","if args.cpu:\n","    args.use_cuda = False\n","elif args.use_cuda:\n","    torch.cuda.manual_seed(args.seed)\n","\n","opt = vars(args)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vxvdxVEvTLqJ"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"oCQDsZmCTpeI"},"source":["#convert userids to userdict key-id(int), val:onehot_vector(tensor)\n","#element in list is str type.\n","def to_onehot_dict(list):\n","    dict={}\n","    length = len(list)\n","    for index, element in enumerate(list):\n","        vector = torch.zeros(1, length).long()\n","        element = int(element)\n","        vector[:, element] = 1.0\n","        dict[element] = vector\n","    return dict\n","\n","def load_list(fname):\n","    list_ = []\n","    with open(fname, encoding=\"utf-8\") as f:\n","        for line in f.readlines():\n","            list_.append(line.strip())\n","    return list_\n","\n","# used for merge dictionaries.\n","def merge_key(dict1, dict2):\n","    res = {**dict1, **dict2}\n","    return res\n","\n","def merge_value(dict1, dict2): # merge and item_cold\n","    for key, value in dict2.items():\n","        if key in dict1.keys():\n","            # if list(set(dict1[key]+value)) the final number of movies-1m is 1000205\n","            new_value = dict1[key]+value\n","            dict1[key] = new_value\n","        else:\n","            print('Unexpected key.')\n","\n","def count_values(dict):\n","    count_val = 0\n","    for key, value in dict.items():\n","        count_val += len(value)\n","    return count_val\n","\n","def construct_dictionary(user_list, total_dict):\n","    dict = {}\n","    for i in range(len(user_list)):\n","        dict[str(user_list[i])] = total_dict[str(user_list[i])]\n","    return dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrF-BoerTZBw"},"source":["### IO\n","def check_dir(d):\n","    if not os.path.exists(d):\n","        print(\"Directory {} does not exist. Exit.\".format(d))\n","        exit(1)\n","\n","\n","def check_files(files):\n","    for f in files:\n","        if f is not None and not os.path.exists(f):\n","            print(\"File {} does not exist. Exit.\".format(f))\n","            exit(1)\n","\n","\n","def ensure_dir(d, verbose=True):\n","    if not os.path.exists(d):\n","        if verbose:\n","            print(\"Directory {} do not exist; creating...\".format(d))\n","        os.makedirs(d)\n","\n","\n","def save_config(config, path, verbose=True):\n","    with open(path, 'w') as outfile:\n","        json.dump(config, outfile, indent=2)\n","    if verbose:\n","        print(\"Config saved to file {}\".format(path))\n","    return config\n","\n","\n","def load_config(path, verbose=True):\n","    with open(path) as f:\n","        config = json.load(f)\n","    if verbose:\n","        print(\"Config loaded from file {}\".format(path))\n","    return config\n","\n","\n","def print_config(config):\n","    info = \"Running with the following configs:\\n\"\n","    for k, v in config.items():\n","        info += \"\\t{} : {}\\n\".format(k, str(v))\n","    print(\"\\n\" + info + \"\\n\")\n","    return\n","\n","\n","class FileLogger(object):\n","    \"\"\"\n","    A file logger that opens the file periodically and write to it.\n","    \"\"\"\n","\n","    def __init__(self, filename, header=None):\n","        self.filename = filename\n","        if os.path.exists(filename):\n","            # remove the old file\n","            os.remove(filename)\n","        if header is not None:\n","            with open(filename, 'w') as out:\n","                print(header, file=out)\n","\n","    def log(self, message):\n","        with open(self.filename, 'a') as out:\n","            print(message)\n","            print(message, file=out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2N-_QNTRTEAB"},"source":["class MyAdagrad(Optimizer):\n","    \"\"\"My modification of the Adagrad optimizer that allows to specify an initial\n","    accumulater value. This mimics the behavior of the default Adagrad implementation\n","    in Tensorflow. The default PyTorch Adagrad uses 0 for initial acculmulator value.\n","    Arguments:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 1e-2)\n","        lr_decay (float, optional): learning rate decay (default: 0)\n","        init_accu_value (float, optional): initial accumulater value.\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","    \"\"\"\n","\n","    def __init__(self, params, lr=1e-2, lr_decay=0, init_accu_value=0.1, weight_decay=0):\n","        defaults = dict(lr=lr, lr_decay=lr_decay, init_accu_value=init_accu_value, \\\n","                weight_decay=weight_decay)\n","        super(MyAdagrad, self).__init__(params, defaults)\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                state['step'] = 0\n","                state['sum'] = torch.ones(p.data.size()).type_as(p.data) *\\\n","                        init_accu_value\n","\n","    def share_memory(self):\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                state['sum'].share_memory_()\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","\n","                grad = p.grad.data\n","                state = self.state[p]\n","\n","                state['step'] += 1\n","\n","                if group['weight_decay'] != 0:\n","                    if p.grad.data.is_sparse:\n","                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients \")\n","                    grad = grad.add(group['weight_decay'], p.data)\n","\n","                clr = group['lr'] / (1 + (state['step'] - 1) * group['lr_decay'])\n","\n","                if p.grad.data.is_sparse:\n","                    grad = grad.coalesce()  # the update is non-linear so indices must be unique\n","                    grad_indices = grad._indices()\n","                    grad_values = grad._values()\n","                    size = torch.Size([x for x in grad.size()])\n","\n","                    def make_sparse(values):\n","                        constructor = type(p.grad.data)\n","                        if grad_indices.dim() == 0 or values.dim() == 0:\n","                            return constructor()\n","                        return constructor(grad_indices, values, size)\n","                    state['sum'].add_(make_sparse(grad_values.pow(2)))\n","                    std = state['sum']._sparse_mask(grad)\n","                    std_values = std._values().sqrt_().add_(1e-10)\n","                    p.data.add_(-clr, make_sparse(grad_values / std_values))\n","                else:\n","                    state['sum'].addcmul_(1, grad, grad)\n","                    std = state['sum'].sqrt().add_(1e-10)\n","                    p.data.addcdiv_(-clr, grad, std)\n","\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"654V_X3gTGwu"},"source":["### torch specific functions\n","def get_optimizer(name, parameters, lr, l2=0):\n","    if name == 'sgd':\n","        return torch.optim.SGD(parameters, lr=lr, weight_decay=l2)\n","    elif name in ['adagrad', 'myadagrad']:\n","        # use my own adagrad to allow for init accumulator value\n","        return MyAdagrad(parameters, lr=lr, init_accu_value=0.1, weight_decay=l2)\n","    elif name == 'adam':\n","        return torch.optim.Adam(parameters, weight_decay=l2) # use default lr\n","    elif name == 'adamax':\n","        return torch.optim.Adamax(parameters, weight_decay=l2) # use default lr\n","    elif name == 'adadelta':\n","        return torch.optim.Adadelta(parameters, lr=lr, weight_decay=l2)\n","    else:\n","        raise Exception(\"Unsupported optimizer: {}\".format(name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVrMNCx6TGuP"},"source":["def change_lr(optimizer, new_lr):\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = new_lr\n","\n","\n","def flatten_indices(seq_lens, width):\n","    flat = []\n","    for i, l in enumerate(seq_lens):\n","        for j in range(l):\n","            flat.append(i * width + j)\n","    return flat\n","\n","\n","def set_cuda(var, cuda):\n","    if cuda:\n","        return var.cuda()\n","    return var\n","\n","\n","def keep_partial_grad(grad, topk):\n","    \"\"\"\n","    Keep only the topk rows of grads.\n","    \"\"\"\n","    assert topk < grad.size(0)\n","    grad.data[topk:].zero_()\n","    return grad\n","\n","### model IO\n","def save(model, optimizer, opt, filename):\n","    params = {\n","        'model': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'config': opt\n","    }\n","    try:\n","        torch.save(params, filename)\n","    except BaseException:\n","        print(\"[ Warning: model saving failed. ]\")\n","\n","\n","def load(model, optimizer, filename):\n","    try:\n","        dump = torch.load(filename)\n","    except BaseException:\n","        print(\"[ Fail: model loading failed. ]\")\n","    if model is not None:\n","        model.load_state_dict(dump['model'])\n","    if optimizer is not None:\n","        optimizer.load_state_dict(dump['optimizer'])\n","    opt = dump['config']\n","    return model, optimizer, opt\n","\n","\n","def load_config(filename):\n","    try:\n","        dump = torch.load(filename)\n","    except BaseException:\n","        print(\"[ Fail: model loading failed. ]\")\n","    return dump['config']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJAQunbsTGrP"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"o_c54cnQTGok"},"source":["class Preprocess(object):\n","    \"\"\"\n","    Preprocess the training, validation and test data.\n","    Generate the episode-style data.\n","    \"\"\"\n","\n","    def __init__(self, opt):\n","        self.batch_size = opt[\"batch_size\"]\n","        self.opt = opt\n","        # warm data ratio\n","        self.train_ratio = opt['train_ratio']\n","        self.valid_ratio = opt['valid_ratio']\n","        self.test_ratio = 1 - self.train_ratio - self.valid_ratio\n","        self.dataset_path = opt[\"data_dir\"]\n","        self.support_size = opt['support_size']\n","        self.query_size = opt['query_size']\n","        self.max_len = opt['max_len']\n","        # save one-hot dimension length\n","        uf_dim, if_dim = self.preprocess(self.dataset_path)\n","        self.uf_dim = uf_dim\n","        self.if_dim = if_dim\n","\n","    def preprocess(self, dataset_path):\n","        \"\"\" Preprocess the data and convert to ids. \"\"\"\n","        #Create training-validation-test datasets\n","        print('Create training, validation and test data from scratch!')\n","        with open('./{}/interaction_dict_x.json'.format(dataset_path), 'r', encoding='utf-8') as f:\n","            inter_dict_x = json.loads(f.read())\n","        with open('./{}/interaction_dict_y.json'.format(dataset_path), 'r', encoding='utf-8') as f:\n","            inter_dict_y = json.loads(f.read())\n","        print('The size of total interactions is %d.' % (count_values(inter_dict_x)))  # 42346\n","        assert count_values(inter_dict_x) == count_values(inter_dict_y)\n","\n","        with open('./{}/user_list.json'.format(dataset_path), 'r', encoding='utf-8') as f:\n","            userids = json.loads(f.read())\n","\n","        with open('./{}/item_list.json'.format(dataset_path), 'r', encoding='utf-8') as f:\n","            itemids = json.loads(f.read())\n","\n","        #userids = list(inter_dict_x.keys())\n","        random.shuffle(userids)\n","        warm_user_size = int(len(userids) * self.train_ratio)\n","        valid_user_size = int(len(userids) * self.valid_ratio)\n","        warm_users = userids[:warm_user_size]\n","        valid_users = userids[warm_user_size:warm_user_size+valid_user_size]\n","        cold_users = userids[warm_user_size+valid_user_size:]\n","        assert len(userids) == len(warm_users)+len(valid_users)+len(cold_users)\n","\n","\n","            # Construct the training data dict\n","        training_dict_x = construct_dictionary(warm_users, inter_dict_x)\n","        training_dict_y = construct_dictionary(warm_users, inter_dict_y)\n","\n","            #Avoid the new items shown in test data in the case of cold user.\n","        item_set = set()\n","        for i in training_dict_x.values():\n","            i = set(i)\n","            item_set = item_set.union(i)\n","\n","        # Construct one-hot dictionary\n","        user_dict = to_onehot_dict(userids)\n","        # only items contained in all data are encoded.\n","        item_dict = to_onehot_dict(itemids)\n","\n","        # This part of data is not used, so we do not process it temporally.\n","        valid_dict_x = construct_dictionary(valid_users, inter_dict_x)\n","        valid_dict_y = construct_dictionary(valid_users, inter_dict_y)\n","        assert count_values(valid_dict_x) == count_values(valid_dict_y)\n","\n","        test_dict_x = construct_dictionary(cold_users, inter_dict_x)\n","        test_dict_y = construct_dictionary(cold_users, inter_dict_y)\n","        assert count_values(test_dict_x) == count_values(test_dict_y)\n","\n","        print('Before delete new items in test data, test data has %d interactions.' % (count_values(test_dict_x)))\n","\n","        #Delete the new items in test data.\n","        unseen_count = 0\n","        for key, value in test_dict_x.items():\n","            assert len(value) == len(test_dict_y[key])\n","            unseen_item_index = [index for index, i in enumerate(value) if i not in item_set]\n","            unseen_count+=len(unseen_item_index)\n","            if len(unseen_item_index) == 0:\n","                continue\n","            else:\n","                new_value_x = [element for index, element in enumerate(value) if index not in unseen_item_index]\n","                new_value_y = [test_dict_y[key][index] for index, element in enumerate(value) if index not in unseen_item_index]\n","                test_dict_x[key] = new_value_x\n","                test_dict_y[key] = new_value_y\n","        print('After delete new items in test data, test data has %d interactions.' % (count_values(test_dict_x)))\n","        assert count_values(test_dict_x) == count_values(test_dict_y)\n","        print('The number of total unseen interactions is %d.' % (unseen_count))\n","\n","        pickle.dump(training_dict_x, open(\"{}/training_dict_x_{:2f}.pkl\".format(dataset_path, self.train_ratio), \"wb\"))\n","        pickle.dump(training_dict_y, open(\"{}/training_dict_y_{:2f}.pkl\".format(dataset_path, self.train_ratio), \"wb\"))\n","        pickle.dump(valid_dict_x, open(\"{}/valid_dict_x_{:2f}.pkl\".format(dataset_path, self.valid_ratio), \"wb\"))\n","        pickle.dump(valid_dict_y, open(\"{}/valid_dict_y_{:2f}.pkl\".format(dataset_path, self.valid_ratio), \"wb\"))\n","        pickle.dump(test_dict_x, open(\"{}/test_dict_x_{:2f}.pkl\".format(dataset_path, self.test_ratio), \"wb\"))\n","        pickle.dump(test_dict_y, open(\"{}/test_dict_y_{:2f}.pkl\".format(dataset_path, self.test_ratio), \"wb\"))\n","\n","        def generate_episodes(dict_x, dict_y, category, support_size, query_size, max_len, dir=\"log\"):\n","            idx = 0\n","            if not os.path.exists(\"{}/{}/{}\".format(dataset_path, category, dir)):\n","                os.makedirs(\"{}/{}/{}\".format(dataset_path, category, dir))\n","                os.makedirs(\"{}/{}/{}\".format(dataset_path, category, \"evidence\"))\n","                for _, user_id in enumerate(dict_x.keys()):\n","                    u_id = int(user_id)\n","                    seen_music_len = len(dict_x[str(u_id)])\n","                    indices = list(range(seen_music_len))\n","                    # filter some users with their interactions, i.e., tasks\n","                    if seen_music_len < (support_size + query_size) or seen_music_len > max_len:\n","                        continue\n","                    random.shuffle(indices)\n","                    tmp_x = np.array(dict_x[str(u_id)])\n","                    tmp_y = np.array(dict_y[str(u_id)])\n","\n","                    support_x_app = None\n","                    for m_id in tmp_x[indices[:support_size]]:\n","                        m_id = int(m_id)\n","                        tmp_x_converted = torch.cat((item_dict[m_id], user_dict[u_id]), 1)\n","                        try:\n","                            support_x_app = torch.cat((support_x_app, tmp_x_converted), 0)\n","                        except:\n","                            support_x_app = tmp_x_converted\n","\n","                    query_x_app = None\n","                    for m_id in tmp_x[indices[support_size:]]:\n","                        m_id = int(m_id)\n","                        u_id = int(user_id)\n","                        tmp_x_converted = torch.cat((item_dict[m_id], user_dict[u_id]), 1)\n","                        try:\n","                            query_x_app = torch.cat((query_x_app, tmp_x_converted), 0)\n","                        except:\n","                            query_x_app = tmp_x_converted\n","\n","                    support_y_app = torch.FloatTensor(tmp_y[indices[:support_size]])\n","                    query_y_app = torch.FloatTensor(tmp_y[indices[support_size:]])\n","\n","                    pickle.dump(support_x_app, open(\"{}/{}/{}/supp_x_{}.pkl\".format(dataset_path, category, dir, idx), \"wb\"))\n","                    pickle.dump(support_y_app, open(\"{}/{}/{}/supp_y_{}.pkl\".format(dataset_path, category, dir, idx), \"wb\"))\n","                    pickle.dump(query_x_app, open(\"{}/{}/{}/query_x_{}.pkl\".format(dataset_path, category, dir, idx), \"wb\"))\n","                    pickle.dump(query_y_app, open(\"{}/{}/{}/query_y_{}.pkl\".format(dataset_path, category, dir, idx), \"wb\"))\n","                    # used for evidence candidate selection\n","                    with open(\"{}/{}/{}/supp_x_{}_u_m_ids.txt\".format(dataset_path, category, \"evidence\", idx), \"w\") as f:\n","                        for m_id in tmp_x[indices[:support_size]]:\n","                            f.write(\"{}\\t{}\\n\".format(u_id, m_id))\n","                    with open(\"{}/{}/{}/query_x_{}_u_m_ids.txt\".format(dataset_path, category, \"evidence\", idx), \"w\") as f:\n","                        for m_id in tmp_x[indices[support_size:]]:\n","                            f.write(\"{}\\t{}\\n\".format(u_id, m_id))\n","                    idx+=1\n","\n","        print(\"Generate eposide data for training.\")\n","        generate_episodes(training_dict_x, training_dict_y, \"training\", self.support_size, self.query_size, self.max_len)\n","        print(\"Generate eposide data for validation.\")\n","        generate_episodes(valid_dict_x, valid_dict_y, \"validation\", self.support_size, self.query_size, self.max_len)\n","        print(\"Generate eposide data for testing.\")\n","        generate_episodes(test_dict_x, test_dict_y, \"testing\", self.support_size, self.query_size, self.max_len)\n","\n","        return len(userids), len(itemids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"keJ-Uj4jUHO9"},"source":["## Model Definition"]},{"cell_type":"markdown","metadata":{"id":"26Yb8kiSadxb"},"source":["TaNP includes the encoder $‚Ñé_\\theta$, the customization module (task identity network $ùëö_\\phi$ and global pool ùë®) and the adaptive decoder $ùëî_{\\omegaùëñ}$. Both of $ùëÜ_ùëñ$ and $\\tau_ùëñ$ are encoded by $‚Ñé_\\theta$ to generate the variational prior and posterior, respectively. The final task embedding $ùíê_ùëñ$ learned from the customized module is used to modulate the model parameters of $ùëî_{\\omegaùëñ} \\cdot ùíõ_ùëñ$ sampled from $ùëû(ùíõ_ùëñ|\\tau_ùëñ)$ is concatenated with $ùíô_{ùëñ,ùëó}$ to predict $\\hat{ùë¶}_{ùëñ,ùëó}$ via $ùëî_{\\omegaùëñ}$."]},{"cell_type":"markdown","metadata":{"id":"uYP-fzbwUVvL"},"source":["### Embeddings"]},{"cell_type":"code","metadata":{"id":"93NCqJnOUIjZ"},"source":["class Item(torch.nn.Module):\n","    def __init__(self, config):\n","        super(Item, self).__init__()\n","        self.feature_dim = config['if_dim']\n","        self.first_embedding_dim = config['first_embedding_dim']\n","        self.second_embedding_dim = config['second_embedding_dim']\n","\n","        self.first_embedding_layer = torch.nn.Linear(\n","            in_features=self.feature_dim,\n","            out_features=self.first_embedding_dim,\n","            bias=True\n","        )\n","\n","        self.second_embedding_layer = torch.nn.Linear(\n","            in_features=self.first_embedding_dim,\n","            out_features=self.second_embedding_dim,\n","            bias=True\n","        )\n","\n","    def forward(self, x, vars=None):\n","        first_hidden = self.first_embedding_layer(x)\n","        first_hidden = F.relu(first_hidden)\n","        sec_hidden = self.second_embedding_layer(first_hidden)\n","        return F.relu(sec_hidden)\n","\n","class Movie_item(torch.nn.Module):\n","    def __init__(self, config):\n","        super(Moive_item, self).__init__()\n","        self.num_rate = config['num_rate']\n","        self.num_genre = config['num_genre']\n","        self.num_director = config['num_director']\n","        self.num_actor = config['num_actor']\n","        self.embedding_dim = config['embedding_dim']\n","\n","        self.embedding_rate = torch.nn.Embedding(\n","            num_embeddings=self.num_rate, \n","            embedding_dim=self.embedding_dim\n","        )\n","        \n","        self.embedding_genre = torch.nn.Linear(\n","            in_features=self.num_genre,\n","            out_features=self.embedding_dim,\n","            bias=False\n","        )\n","        \n","        self.embedding_director = torch.nn.Linear(\n","            in_features=self.num_director,\n","            out_features=self.embedding_dim,\n","            bias=False\n","        )\n","        \n","        self.embedding_actor = torch.nn.Linear(\n","            in_features=self.num_actor,\n","            out_features=self.embedding_dim,\n","            bias=False\n","        )\n","\n","    def forward(self, rate_idx, genre_idx, director_idx, actors_idx, vars=None):\n","        rate_emb = self.embedding_rate(rate_idx)\n","        genre_emb = self.embedding_genre(genre_idx.float()) / torch.sum(genre_idx.float(), 1).view(-1, 1)\n","        director_emb = self.embedding_director(director_idx.float()) / torch.sum(director_idx.float(), 1).view(-1, 1)\n","        actors_emb = self.embedding_actor(actors_idx.float()) / torch.sum(actors_idx.float(), 1).view(-1, 1)\n","        return torch.cat((rate_emb, genre_emb, director_emb, actors_emb), 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ox55_5OgUR6q"},"source":["class User(torch.nn.Module):\n","    def __init__(self, config):\n","        super(User, self).__init__()\n","        self.feature_dim = config['uf_dim']\n","        self.first_embedding_dim = config['first_embedding_dim']\n","        self.second_embedding_dim = config['second_embedding_dim']\n","\n","        self.first_embedding_layer = torch.nn.Linear(\n","            in_features=self.feature_dim,\n","            out_features=self.first_embedding_dim,\n","            bias=True\n","        )\n","\n","        self.second_embedding_layer = torch.nn.Linear(\n","            in_features=self.first_embedding_dim,\n","            out_features=self.second_embedding_dim,\n","            bias=True\n","        )\n","\n","    def forward(self, x, vars=None):\n","        first_hidden = self.first_embedding_layer(x)\n","        first_hidden = F.relu(first_hidden)\n","        sec_hidden = self.second_embedding_layer(first_hidden)\n","        return F.relu(sec_hidden)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT5VoHl0UQh9"},"source":["class Movie_user(torch.nn.Module):\n","    def __init__(self, config):\n","        super(Movie_user, self).__init__()\n","        self.num_gender = config['num_gender']\n","        self.num_age = config['num_age']\n","        self.num_occupation = config['num_occupation']\n","        self.num_zipcode = config['num_zipcode']\n","        self.embedding_dim = config['embedding_dim']\n","\n","        self.embedding_gender = torch.nn.Embedding(\n","            num_embeddings=self.num_gender,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embedding_age = torch.nn.Embedding(\n","            num_embeddings=self.num_age,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embedding_occupation = torch.nn.Embedding(\n","            num_embeddings=self.num_occupation,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","        self.embedding_area = torch.nn.Embedding(\n","            num_embeddings=self.num_zipcode,\n","            embedding_dim=self.embedding_dim\n","        )\n","\n","    def forward(self, gender_idx, age_idx, occupation_idx, area_idx):\n","        gender_emb = self.embedding_gender(gender_idx)\n","        age_emb = self.embedding_age(age_idx)\n","        occupation_emb = self.embedding_occupation(occupation_idx)\n","        area_emb = self.embedding_area(area_idx)\n","        return torch.cat((gender_emb, age_emb, occupation_emb, area_emb), 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BG3qnUnjUPTF"},"source":["class Encoder(nn.Module):\n","    #Maps an (x_i, y_i) pair to a representation r_i.\n","    # Add the dropout into encoder ---03.31\n","    def __init__(self, x_dim, y_dim, h1_dim, h2_dim, z1_dim, dropout_rate):\n","        super(Encoder, self).__init__()\n","\n","        self.x_dim = x_dim\n","        self.y_dim = y_dim\n","        self.h1_dim = h1_dim\n","        self.h2_dim = h2_dim\n","        self.z1_dim = z1_dim\n","        self.dropout_rate = dropout_rate\n","\n","        layers = [nn.Linear(self.x_dim + self.y_dim, self.h1_dim),\n","                  torch.nn.Dropout(self.dropout_rate),\n","                  nn.ReLU(inplace=True),\n","                  nn.Linear(self.h1_dim, self.h2_dim),\n","                  torch.nn.Dropout(self.dropout_rate),\n","                  nn.ReLU(inplace=True),\n","                  nn.Linear(self.h2_dim, self.z1_dim)]\n","\n","        self.input_to_hidden = nn.Sequential(*layers)\n","\n","    def forward(self, x, y):\n","        y = y.view(-1, 1)\n","        input_pairs = torch.cat((x, y), dim=1)\n","        return self.input_to_hidden(input_pairs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OBDuceVUOFr"},"source":["class MuSigmaEncoder(nn.Module):\n","    def __init__(self, z1_dim, z2_dim, z_dim):\n","        super(MuSigmaEncoder, self).__init__()\n","\n","        self.z1_dim = z1_dim\n","        self.z2_dim = z2_dim\n","        self.z_dim = z_dim\n","        self.z_to_hidden = nn.Linear(self.z1_dim, self.z2_dim)\n","        self.hidden_to_mu = nn.Linear(self.z2_dim, z_dim)\n","        self.hidden_to_logsigma = nn.Linear(self.z2_dim, z_dim)\n","\n","    def forward(self, z_input):\n","        hidden = torch.relu(self.z_to_hidden(z_input))\n","        mu = self.hidden_to_mu(hidden)\n","        log_sigma = self.hidden_to_logsigma(hidden)\n","        std = torch.exp(0.5 * log_sigma)\n","        eps = torch.randn_like(std)\n","        z = eps.mul(std).add_(mu)\n","        return mu, log_sigma, z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4Gt1yo0UMxL"},"source":["class TaskEncoder(nn.Module):\n","    def __init__(self, x_dim, y_dim, h1_dim, h2_dim, final_dim, dropout_rate):\n","        super(TaskEncoder, self).__init__()\n","        self.x_dim = x_dim\n","        self.y_dim = y_dim\n","        self.h1_dim = h1_dim\n","        self.h2_dim = h2_dim\n","        self.final_dim = final_dim\n","        self.dropout_rate = dropout_rate\n","        layers = [nn.Linear(self.x_dim + self.y_dim, self.h1_dim),\n","                  torch.nn.Dropout(self.dropout_rate),\n","                  nn.ReLU(inplace=True),\n","                  nn.Linear(self.h1_dim, self.h2_dim),\n","                  torch.nn.Dropout(self.dropout_rate),\n","                  nn.ReLU(inplace=True),\n","                  nn.Linear(self.h2_dim, self.final_dim)]\n","\n","        self.input_to_hidden = nn.Sequential(*layers)\n","\n","    def forward(self, x, y):\n","        y = y.view(-1, 1)\n","        input_pairs = torch.cat((x, y), dim=1)\n","        return self.input_to_hidden(input_pairs)\n","\n","class MemoryUnit(nn.Module):\n","    # clusters_k is k keys\n","    def __init__(self, clusters_k, emb_size, temperature):\n","        super(MemoryUnit, self).__init__()\n","        self.clusters_k = clusters_k\n","        self.embed_size = emb_size\n","        self.temperature = temperature\n","        self.array = nn.Parameter(init.xavier_uniform_(torch.FloatTensor(self.clusters_k, self.embed_size)))\n","\n","    def forward(self, task_embed):\n","        res = torch.norm(task_embed-self.array, p=2, dim=1, keepdim=True)\n","        res = torch.pow((res / self.temperature) + 1, (self.temperature + 1) / -2)\n","        # 1*k\n","        C = torch.transpose(res / res.sum(), 0, 1)\n","        # 1*k, k*d, 1*d\n","        value = torch.mm(C, self.array)\n","        # simple add operation\n","        new_task_embed = value + task_embed\n","        # calculate target distribution\n","        return C, new_task_embed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7nG1TReULk4"},"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Maps target input x_target and z, r to predictions y_target.\n","    \"\"\"\n","    def __init__(self, x_dim, z_dim, task_dim, h1_dim, h2_dim, h3_dim, y_dim, dropout_rate):\n","        super(Decoder, self).__init__()\n","        self.x_dim = x_dim\n","        self.z_dim = z_dim\n","        self.task_dim = task_dim\n","        self.h1_dim = h1_dim\n","        self.h2_dim = h2_dim\n","        self.h3_dim = h3_dim\n","        self.y_dim = y_dim\n","        self.dropout_rate = dropout_rate\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","\n","        self.hidden_layer_1 = nn.Linear(self.x_dim + self.z_dim, self.h1_dim)\n","        self.hidden_layer_2 = nn.Linear(self.h1_dim, self.h2_dim)\n","        self.hidden_layer_3 = nn.Linear(self.h2_dim, self.h3_dim)\n","\n","        self.film_layer_1_beta = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","        self.film_layer_1_gamma = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","        self.film_layer_2_beta = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","        self.film_layer_2_gamma = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","        self.film_layer_3_beta = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","        self.film_layer_3_gamma = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","\n","        self.final_projection = nn.Linear(self.h3_dim, self.y_dim)\n","\n","    def forward(self, x, z, task):\n","        interaction_size, _ = x.size()\n","        z = z.unsqueeze(0).repeat(interaction_size, 1)\n","        # Input is concatenation of z with every row of x\n","        inputs = torch.cat((x, z), dim=1)\n","        hidden_1 = self.hidden_layer_1(inputs)\n","        beta_1 = torch.tanh(self.film_layer_1_beta(task))\n","        gamma_1 = torch.tanh(self.film_layer_1_gamma(task))\n","        hidden_1 = torch.mul(hidden_1, gamma_1) + beta_1\n","        hidden_1 = self.dropout(hidden_1)\n","        hidden_2 = F.relu(hidden_1)\n","\n","        hidden_2 = self.hidden_layer_2(hidden_2)\n","        beta_2 = torch.tanh(self.film_layer_2_beta(task))\n","        gamma_2 = torch.tanh(self.film_layer_2_gamma(task))\n","        hidden_2 = torch.mul(hidden_2, gamma_2) + beta_2\n","        hidden_2 = self.dropout(hidden_2)\n","        hidden_3 = F.relu(hidden_2)\n","\n","        hidden_3 = self.hidden_layer_3(hidden_3)\n","        beta_3 = torch.tanh(self.film_layer_3_beta(task))\n","        gamma_3 = torch.tanh(self.film_layer_3_gamma(task))\n","        hidden_final = torch.mul(hidden_3, gamma_3) + beta_3\n","        hidden_final = self.dropout(hidden_final)\n","        hidden_final = F.relu(hidden_final)\n","\n","        y_pred = self.final_projection(hidden_final)\n","        return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edivGiDDUJ_V"},"source":["class Gating_Decoder(nn.Module):\n","\n","    def __init__(self, x_dim, z_dim, task_dim, h1_dim, h2_dim, h3_dim, y_dim, dropout_rate):\n","        super(Gating_Decoder, self).__init__()\n","        self.x_dim = x_dim\n","        self.z_dim = z_dim\n","        self.task_dim = task_dim\n","        self.h1_dim = h1_dim\n","        self.h2_dim = h2_dim\n","        self.h3_dim = h3_dim\n","        self.y_dim = y_dim\n","        self.dropout_rate = dropout_rate\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","\n","        self.hidden_layer_1 = nn.Linear(self.x_dim + self.z_dim, self.h1_dim)\n","        self.hidden_layer_2 = nn.Linear(self.h1_dim, self.h2_dim)\n","        self.hidden_layer_3 = nn.Linear(self.h2_dim, self.h3_dim)\n","\n","        self.film_layer_1_beta = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","        self.film_layer_1_gamma = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","        self.film_layer_1_eta = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","        self.film_layer_1_delta = nn.Linear(self.task_dim, self.h1_dim, bias=False)\n","\n","        self.film_layer_2_beta = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","        self.film_layer_2_gamma = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","        self.film_layer_2_eta = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","        self.film_layer_2_delta = nn.Linear(self.task_dim, self.h2_dim, bias=False)\n","\n","\n","        self.film_layer_3_beta = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","        self.film_layer_3_gamma = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","        self.film_layer_3_eta = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","        self.film_layer_3_delta = nn.Linear(self.task_dim, self.h3_dim, bias=False)\n","\n","\n","        self.final_projection = nn.Linear(self.h3_dim, self.y_dim)\n","\n","    def forward(self, x, z, task):\n","        interaction_size, _ = x.size()\n","        z = z.unsqueeze(0).repeat(interaction_size, 1)\n","        # Input is concatenation of z with every row of x\n","        inputs = torch.cat((x, z), dim=1)\n","        hidden_1 = self.hidden_layer_1(inputs)\n","        beta_1 = torch.tanh(self.film_layer_1_beta(task))\n","        gamma_1 = torch.tanh(self.film_layer_1_gamma(task))\n","        eta_1 = torch.tanh(self.film_layer_1_eta(task))\n","        delta_1 = torch.sigmoid(self.film_layer_1_delta(task))\n","\n","        gamma_1 = gamma_1 * delta_1 + eta_1 * (1-delta_1)\n","        beta_1 = beta_1 * delta_1 + eta_1 * (1-delta_1)\n","\n","        hidden_1 = torch.mul(hidden_1, gamma_1) + beta_1\n","        hidden_1 = self.dropout(hidden_1)\n","        hidden_2 = F.relu(hidden_1)\n","\n","        hidden_2 = self.hidden_layer_2(hidden_2)\n","        beta_2 = torch.tanh(self.film_layer_2_beta(task))\n","        gamma_2 = torch.tanh(self.film_layer_2_gamma(task))\n","        eta_2 = torch.tanh(self.film_layer_2_eta(task))\n","        delta_2 = torch.sigmoid(self.film_layer_2_delta(task))\n","\n","        gamma_2 = gamma_2 * delta_2 + eta_2 * (1 - delta_2)\n","        beta_2 = beta_2 * delta_2 + eta_2 * (1 - delta_2)\n","\n","\n","        hidden_2 = torch.mul(hidden_2, gamma_2) + beta_2\n","        hidden_2 = self.dropout(hidden_2)\n","        hidden_3 = F.relu(hidden_2)\n","        hidden_3 = self.hidden_layer_3(hidden_3)\n","        beta_3 = torch.tanh(self.film_layer_3_beta(task))\n","        gamma_3 = torch.tanh(self.film_layer_3_gamma(task))\n","        eta_3 = torch.tanh(self.film_layer_3_eta(task))\n","        delta_3 = torch.sigmoid(self.film_layer_3_delta(task))\n","\n","        gamma_3 = gamma_3 * delta_3 + eta_3 * (1 - delta_3)\n","        beta_3 = beta_3 * delta_3 + eta_3 * (1 - delta_3)\n","\n","        hidden_final = torch.mul(hidden_3, gamma_3) + beta_3\n","        hidden_final = self.dropout(hidden_final)\n","        hidden_final = F.relu(hidden_final)\n","\n","        y_pred = self.final_projection(hidden_final)\n","        return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1G27QCrDVCO1"},"source":["### TaNP"]},{"cell_type":"markdown","metadata":{"id":"QpkQ2ri90z_5"},"source":["<p><center><img src='_images/T722684_2.png'></center></p>"]},{"cell_type":"code","metadata":{"id":"cg1xj6X_VEVH"},"source":["class NP(nn.Module):\n","    def __init__(self, config):\n","        super(NP, self).__init__()\n","        self.x_dim = config['second_embedding_dim'] * 2\n","        # use one-hot or not?\n","        self.y_dim = 1\n","        self.z1_dim = config['z1_dim']\n","        self.z2_dim = config['z2_dim']\n","        # z is the dimension size of mu and sigma.\n","        self.z_dim = config['z_dim']\n","        # the dimension size of rc.\n","        self.enc_h1_dim = config['enc_h1_dim']\n","        self.enc_h2_dim = config['enc_h2_dim']\n","\n","        self.dec_h1_dim = config['dec_h1_dim']\n","        self.dec_h2_dim = config['dec_h2_dim']\n","        self.dec_h3_dim = config['dec_h3_dim']\n","\n","        self.taskenc_h1_dim = config['taskenc_h1_dim']\n","        self.taskenc_h2_dim = config['taskenc_h2_dim']\n","        self.taskenc_final_dim = config['taskenc_final_dim']\n","\n","        self.clusters_k = config['clusters_k']\n","        self.temperture = config['temperature']\n","        self.dropout_rate = config['dropout_rate']\n","\n","        # Initialize networks\n","        self.item_emb = Item(config)\n","        self.user_emb = User(config)\n","        # This encoder is used to generated z actually, it is a latent encoder in ANP.\n","        self.xy_to_z = Encoder(self.x_dim, self.y_dim, self.enc_h1_dim, self.enc_h2_dim, self.z1_dim, self.dropout_rate)\n","        self.z_to_mu_sigma = MuSigmaEncoder(self.z1_dim, self.z2_dim, self.z_dim)\n","        # This encoder is used to generated r actually, it is a deterministic encoder in ANP.\n","        self.xy_to_task = TaskEncoder(self.x_dim, self.y_dim, self.taskenc_h1_dim, self.taskenc_h2_dim, self.taskenc_final_dim,\n","                                      self.dropout_rate)\n","        self.memoryunit = MemoryUnit(self.clusters_k, self.taskenc_final_dim, self.temperture)\n","        #self.xz_to_y = Gating_Decoder(self.x_dim, self.z_dim, self.taskenc_final_dim, self.dec_h1_dim, self.dec_h2_dim, self.dec_h3_dim, self.y_dim, self.dropout_rate)\n","        self.xz_to_y = Decoder(self.x_dim, self.z_dim, self.taskenc_final_dim, self.dec_h1_dim, self.dec_h2_dim, self.dec_h3_dim, self.y_dim, self.dropout_rate)\n","\n","    def aggregate(self, z_i):\n","        return torch.mean(z_i, dim=0)\n","\n","    def xy_to_mu_sigma(self, x, y):\n","        # Encode each point into a representation r_i\n","        z_i = self.xy_to_z(x, y)\n","        # Aggregate representations r_i into a single representation r\n","        z = self.aggregate(z_i)\n","        # Return parameters of distribution\n","        return self.z_to_mu_sigma(z)\n","\n","    # embedding each (item, user) as the x for np\n","    def embedding(self, x):\n","        if_dim = self.item_emb.feature_dim\n","        item_x = Variable(x[:, 0:if_dim], requires_grad=False).float()\n","        user_x = Variable(x[:, if_dim:], requires_grad=False).float()\n","        item_emb = self.item_emb(item_x)\n","        user_emb = self.user_emb(user_x)\n","        x = torch.cat((item_emb, user_emb), 1)\n","        return x\n","\n","    def forward(self, x_context, y_context, x_target, y_target):\n","        x_context_embed = self.embedding(x_context)\n","        x_target_embed = self.embedding(x_target)\n","\n","        if self.training:\n","            # sigma is log_sigma actually\n","            mu_target, sigma_target, z_target = self.xy_to_mu_sigma(x_target_embed, y_target)\n","            mu_context, sigma_context, z_context = self.xy_to_mu_sigma(x_context_embed, y_context)\n","            task = self.xy_to_task(x_context_embed, y_context)\n","            mean_task = self.aggregate(task)\n","            C_distribution, new_task_embed = self.memoryunit(mean_task)\n","            p_y_pred = self.xz_to_y(x_target_embed, z_target, new_task_embed)\n","            return p_y_pred, mu_target, sigma_target, mu_context, sigma_context, C_distribution\n","        else:\n","            mu_context, sigma_context, z_context = self.xy_to_mu_sigma(x_context_embed, y_context)\n","            task = self.xy_to_task(x_context_embed, y_context)\n","            mean_task = self.aggregate(task)\n","            C_distribution, new_task_embed = self.memoryunit(mean_task)\n","            p_y_pred = self.xz_to_y(x_target_embed, z_context, new_task_embed)\n","            return p_y_pred\n","\n","\n","class Trainer(torch.nn.Module):\n","    def __init__(self, config):\n","        self.opt = config\n","        super(Trainer, self).__init__()\n","        self.use_cuda = config['use_cuda']\n","        self.np = NP(self.opt)\n","        self._lambda = config['lambda']\n","        self.optimizer = torch.optim.Adam(self.np.parameters(), lr=config['lr'])\n","\n","    # our kl divergence\n","    def kl_div(self, mu_target, logsigma_target, mu_context, logsigma_context):\n","        target_sigma = torch.exp(logsigma_target)\n","        context_sigma = torch.exp(logsigma_context)\n","        kl_div = (logsigma_context - logsigma_target) - 0.5 + (((target_sigma ** 2) + (mu_target - mu_context) ** 2) / 2 * context_sigma ** 2)\n","        #kl_div = (t.exp(posterior_var) + (posterior_mu-prior_mu) ** 2) / t.exp(prior_var) - 1. + (prior_var - posterior_var)\n","        #kl_div = 0.5 * kl_div.sum()\n","        kl_div = kl_div.sum()\n","        return kl_div\n","\n","    # new kl divergence -- kl(st|sc)\n","    def new_kl_div(self, prior_mu, prior_var, posterior_mu, posterior_var):\n","        kl_div = (torch.exp(posterior_var) + (posterior_mu-prior_mu) ** 2) / torch.exp(prior_var) - 1. + (prior_var - posterior_var)\n","        kl_div = 0.5 * kl_div.sum()\n","        return kl_div\n","\n","    def loss(self, p_y_pred, y_target, mu_target, sigma_target, mu_context, sigma_context):\n","        #print('p_y_pred size is ', p_y_pred.size())\n","        regression_loss = F.mse_loss(p_y_pred, y_target.view(-1, 1))\n","        #print('regession loss size is ', regression_loss.size())\n","        # kl divergence between target and context\n","        #print('regession_loss is ', regression_loss.item())\n","        kl = self.new_kl_div(mu_context, sigma_context, mu_target, sigma_target)\n","        #print('KL_loss is ', kl.item())\n","        return regression_loss+kl\n","\n","    def context_target_split(self, support_set_x, support_set_y, query_set_x, query_set_y):\n","        total_x = torch.cat((support_set_x, query_set_x), 0)\n","        total_y = torch.cat((support_set_y, query_set_y), 0)\n","        total_size = total_x.size(0)\n","        context_min = self.opt['context_min']\n","        context_max = self.opt['context_max']\n","        extra_tar_min = self.opt['target_extra_min']\n","        #here we simply use the total_size as the maximum of target size.\n","        num_context = randint(context_min, context_max)\n","        num_target = randint(extra_tar_min, total_size - num_context)\n","        sampled = np.random.choice(total_size, num_context+num_target, replace=False)\n","        x_context = total_x[sampled[:num_context], :]\n","        y_context = total_y[sampled[:num_context]]\n","        x_target = total_x[sampled, :]\n","        y_target = total_y[sampled]\n","        return x_context, y_context, x_target, y_target\n","\n","    def new_context_target_split(self, support_set_x, support_set_y, query_set_x, query_set_y):\n","        total_x = torch.cat((support_set_x, query_set_x), 0)\n","        total_y = torch.cat((support_set_y, query_set_y), 0)\n","        total_size = total_x.size(0)\n","        context_min = self.opt['context_min']\n","        num_context = np.random.randint(context_min, total_size)\n","        num_target = np.random.randint(0, total_size - num_context)\n","        sampled = np.random.choice(total_size, num_context+num_target, replace=False)\n","        x_context = total_x[sampled[:num_context], :]\n","        y_context = total_y[sampled[:num_context]]\n","        x_target = total_x[sampled, :]\n","        y_target = total_y[sampled]\n","        return x_context, y_context, x_target, y_target\n","\n","    def global_update(self, support_set_xs, support_set_ys, query_set_xs, query_set_ys):\n","        batch_sz = len(support_set_xs)\n","        losses = []\n","        C_distribs = []\n","        if self.use_cuda:\n","            for i in range(batch_sz):\n","                support_set_xs[i] = support_set_xs[i].cuda()\n","                support_set_ys[i] = support_set_ys[i].cuda()\n","                query_set_xs[i] = query_set_xs[i].cuda()\n","                query_set_ys[i] = query_set_ys[i].cuda()\n","        for i in range(batch_sz):\n","            x_context, y_context, x_target, y_target = self.new_context_target_split(support_set_xs[i], support_set_ys[i],\n","                                                                                 query_set_xs[i], query_set_ys[i])\n","            p_y_pred, mu_target, sigma_target, mu_context, sigma_context, C_distribution = self.np(x_context, y_context, x_target,\n","                                                                                  y_target)\n","            C_distribs.append(C_distribution)\n","            loss = self.loss(p_y_pred, y_target, mu_target, sigma_target, mu_context, sigma_context)\n","            #print('Each task has loss: ', loss)\n","            losses.append(loss)\n","        # calculate target distribution for clustering in batch manner.\n","        # batchsize * k\n","        C_distribs = torch.stack(C_distribs)\n","        # batchsize * k\n","        C_distribs_sq = torch.pow(C_distribs, 2)\n","        # 1*k\n","        C_distribs_sum = torch.sum(C_distribs, dim=0, keepdim=True)\n","        # batchsize * k\n","        temp = C_distribs_sq / C_distribs_sum\n","        # batchsize * 1\n","        temp_sum = torch.sum(temp, dim=1, keepdim=True)\n","        target_distribs = temp / temp_sum\n","        # calculate the kl loss\n","        clustering_loss = self._lambda * F.kl_div(C_distribs.log(), target_distribs, reduction='batchmean')\n","        #print('The clustering loss is %.6f' % (clustering_loss.item()))\n","        np_losses_mean = torch.stack(losses).mean(0)\n","        total_loss = np_losses_mean + clustering_loss\n","        self.optimizer.zero_grad()\n","        total_loss.backward()\n","        self.optimizer.step()\n","        return total_loss.item(), C_distribs.cpu().detach().numpy()\n","\n","    def query_rec(self, support_set_xs, support_set_ys, query_set_xs, query_set_ys):\n","        batch_sz = 1\n","        # used for calculating the rmse.\n","        losses_q = []\n","        if self.use_cuda:\n","            for i in range(batch_sz):\n","                support_set_xs[i] = support_set_xs[i].cuda()\n","                support_set_ys[i] = support_set_ys[i].cuda()\n","                query_set_xs[i] = query_set_xs[i].cuda()\n","                query_set_ys[i] = query_set_ys[i].cuda()\n","        for i in range(batch_sz):\n","            #query_set_y_pred = self.forward(support_set_xs[i], support_set_ys[i], query_set_xs[i], num_local_update)\n","            query_set_y_pred = self.np(support_set_xs[i], support_set_ys[i], query_set_xs[i], query_set_ys[i])\n","            # obtain the mean of gaussian distribution\n","            #(interation_size, y_dim)\n","            #query_set_y_pred = query_set_y_pred.loc.detach()\n","            #print('test_y_pred size is ', query_set_y_pred.size())\n","            loss_q = F.mse_loss(query_set_y_pred, query_set_ys[i].view(-1, 1))\n","            losses_q.append(loss_q)\n","        losses_q = torch.stack(losses_q).mean(0)\n","        output_list, recommendation_list = query_set_y_pred.view(-1).sort(descending=True)\n","        return losses_q.item(), recommendation_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee3MqBcWUf1j"},"source":["## Evaluation modules"]},{"cell_type":"markdown","metadata":{"id":"R5hFfpM3T4t3"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"DcoNb06IT5fW"},"source":["def AP(ranked_list, ground_truth, topn):\n","    hits, sum_precs = 0, 0.0\n","    t = [a for a in ground_truth]\n","    t.sort(reverse=True)\n","    t=t[:topn]\n","    for i in range(topn):\n","        id = ranked_list[i]\n","        if ground_truth[id] in t:\n","            hits += 1\n","            sum_precs += hits / (i+1.0)\n","            t.remove(ground_truth[id])\n","    if hits > 0:\n","        return sum_precs / topn\n","    else:\n","        return 0.0\n","\n","def RR(ranked_list, ground_truth,topn):\n","    t = [a for a in ground_truth]\n","    t.sort(reverse=True)\n","    t = t[:topn]\n","    for i in range(topn):\n","        id = ranked_list[i]\n","        if ground_truth[id] in t:\n","            return 1 / (i + 1.0)\n","    return 0\n","\n","def precision(ranked_list,ground_truth,topn):\n","    t = [a for a in ground_truth]\n","    t.sort(reverse=True)\n","    t = t[:topn]\n","    hits = 0\n","    for i in range(topn):\n","        id = ranked_list[i]\n","        if ground_truth[id] in t:\n","            t.remove(ground_truth[id])\n","            hits += 1\n","    pre = hits/topn\n","    return pre\n","\n","\n","def nDCG(ranked_list, ground_truth, topn):\n","    dcg = 0\n","    idcg = IDCG(ground_truth, topn)\n","    # print(ranked_list)\n","    # input()\n","    for i in range(topn):\n","        id = ranked_list[i]\n","        dcg += ((2 ** ground_truth[id]) -1)/ math.log(i+2, 2)\n","    # print('dcg is ', dcg, \" n is \", topn)\n","    # print('idcg is ', idcg, \" n is \", topn)\n","    return dcg / idcg\n","\n","def IDCG(ground_truth,topn):\n","    t = [a for a in ground_truth]\n","    t.sort(reverse=True)\n","    idcg = 0\n","    for i in range(topn):\n","        idcg += ((2**t[i]) - 1) / math.log(i+2, 2)\n","    return idcg\n","\n","def add_metric(recommend_list, ALL_group_list, precision_list, ap_list, ndcg_list, topn):\n","    ndcg = nDCG(recommend_list, ALL_group_list, topn)\n","    ap = AP(recommend_list, ALL_group_list, topn)\n","    pre = precision(recommend_list, ALL_group_list, topn)\n","    precision_list.append(pre)\n","    ap_list.append(ap)\n","    ndcg_list.append(ndcg)\n","\n","\n","\n","def cal_metric(precision_list,ap_list,ndcg_list):\n","    mpre = sum(precision_list) / len(precision_list)\n","    map = sum(ap_list) / len(ap_list)\n","    mndcg = sum(ndcg_list) / len(ndcg_list)\n","    return mpre, mndcg, map"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwmoOPmMUi4L"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"gueZYV8CUh4F"},"source":["def testing(trainer, opt, test_dataset):\n","    test_dataset_len = len(test_dataset)\n","    #batch_size = opt[\"batch_size\"]\n","    minibatch_size = 1\n","    a, b, c, d = zip(*test_dataset)\n","    trainer.eval()\n","    all_loss = 0\n","    pre5 = []\n","    ap5 = []\n","    ndcg5 = []\n","    pre7 = []\n","    ap7 = []\n","    ndcg7 = []\n","    pre10 = []\n","    ap10 = []\n","    ndcg10 = []\n","    for i in range(test_dataset_len):\n","        try:\n","            supp_xs = list(a[minibatch_size * i:minibatch_size * (i + 1)])\n","            supp_ys = list(b[minibatch_size * i:minibatch_size * (i + 1)])\n","            query_xs = list(c[minibatch_size * i:minibatch_size * (i + 1)])\n","            query_ys = list(d[minibatch_size * i:minibatch_size * (i + 1)])\n","        except IndexError:\n","            continue\n","        test_loss, recommendation_list = trainer.query_rec(supp_xs, supp_ys, query_xs, query_ys)\n","        all_loss += test_loss\n","\n","        add_metric(recommendation_list, query_ys[0].cpu().detach().numpy(), pre5, ap5, ndcg5, 5)\n","        add_metric(recommendation_list, query_ys[0].cpu().detach().numpy(), pre7, ap7, ndcg7, 7)\n","        add_metric(recommendation_list, query_ys[0].cpu().detach().numpy(), pre10, ap10, ndcg10, 10)\n","\n","    mpre5, mndcg5, map5 = cal_metric(pre5, ap5, ndcg5)\n","    mpre7, mndcg7, map7 = cal_metric(pre7, ap7, ndcg7)\n","    mpre10, mndcg10, map10 = cal_metric(pre10, ap10, ndcg10)\n","\n","    return mpre5, mndcg5, map5, mpre7, mndcg7, map7, mpre10, mndcg10, map10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRhfeDkuUpjQ"},"source":["## Training and Evaluation"]},{"cell_type":"code","metadata":{"id":"DcrOaTdSUq7h"},"source":["def training(trainer, opt, train_dataset, test_dataset, batch_size, num_epoch, model_save=True, model_filename=None, logger=None):\n","    training_set_size = len(train_dataset)\n","    for epoch in range(num_epoch):\n","        random.shuffle(train_dataset)\n","        num_batch = int(training_set_size / batch_size)\n","        a, b, c, d = zip(*train_dataset)\n","        trainer.train()\n","        all_C_distribs = []\n","        for i in range(num_batch):\n","            try:\n","                supp_xs = list(a[batch_size*i:batch_size*(i+1)])\n","                supp_ys = list(b[batch_size*i:batch_size*(i+1)])\n","                query_xs = list(c[batch_size*i:batch_size*(i+1)])\n","                query_ys = list(d[batch_size*i:batch_size*(i+1)])\n","            except IndexError:\n","                continue\n","            train_loss, batch_C_distribs = trainer.global_update(supp_xs, supp_ys, query_xs, query_ys)\n","            all_C_distribs.append(batch_C_distribs)\n","\n","        P5, NDCG5, MAP5, P7, NDCG7, MAP7, P10, NDCG10, MAP10 = testing(trainer, opt, test_dataset)\n","        logger.log(\n","            \"{}\\t{:.6f}\\t TOP-5 {:.4f}\\t{:.4f}\\t{:.4f}\\t TOP-7: {:.4f}\\t{:.4f}\\t{:.4f}\"\n","            \"\\t TOP-10: {:.4f}\\t{:.4f}\\t{:.4f}\".\n","                format(epoch, train_loss, P5, NDCG5, MAP5, P7, NDCG7, MAP7, P10, NDCG10, MAP10))\n","        if epoch == (num_epoch-1):\n","            with open('output_att', 'wb') as fp:\n","                pickle.dump(all_C_distribs, fp)\n","\n","    if model_save:\n","        torch.save(trainer.state_dict(), model_filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tofDHS2uWG_w","executionInfo":{"status":"ok","timestamp":1635851932664,"user_tz":-330,"elapsed":1023,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"3cf1dc5d-f881-4957-80b8-a7406d253183"},"source":["# print model info\n","print_config(opt)\n","ensure_dir(opt[\"model_save_dir\"], verbose=True)\n","\n","# save model config\n","save_config(opt, opt[\"model_save_dir\"] + \"/\" +opt[\"id\"] + '.config', verbose=True)\n","\n","# record training log\n","file_logger = FileLogger(opt[\"model_save_dir\"] + '/' + opt['id'] + \".log\",\n","                                header=\"# epoch\\ttrain_loss\\tprecision5\\tNDCG5\\tMAP5\\tprecision7\"\n","                                       \"\\tNDCG7\\tMAP7\\tprecision10\\tNDCG10\\tMAP10\")\n","\n","preprocess = Preprocess(opt)\n","print(\"Preprocess is done.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running with the following configs:\n","\tdata_dir : data/lastfm_20\n","\tmodel_save_dir : save_model_dir\n","\tid : 1\n","\tfirst_embedding_dim : 32\n","\tsecond_embedding_dim : 16\n","\tz1_dim : 32\n","\tz2_dim : 32\n","\tz_dim : 32\n","\tenc_h1_dim : 64\n","\tenc_h2_dim : 64\n","\ttaskenc_h1_dim : 128\n","\ttaskenc_h2_dim : 64\n","\ttaskenc_final_dim : 64\n","\tclusters_k : 7\n","\ttemperature : 1.0\n","\tlambda : 0.1\n","\tdec_h1_dim : 128\n","\tdec_h2_dim : 128\n","\tdec_h3_dim : 128\n","\tdropout_rate : 0\n","\tlr : 0.0001\n","\toptim : adam\n","\tnum_epoch : 150\n","\tbatch_size : 32\n","\ttrain_ratio : 0.7\n","\tvalid_ratio : 0.1\n","\tseed : 2020\n","\tsave : 0\n","\tuse_cuda : False\n","\tcpu : False\n","\tsupport_size : 20\n","\tquery_size : 10\n","\tmax_len : 200\n","\tcontext_min : 20\n","\n","\n","Directory save_model_dir do not exist; creating...\n","Config saved to file save_model_dir/1.config\n","Create training, validation and test data from scratch!\n","The size of total interactions is 42346.\n","Before delete new items in test data, test data has 8384 interactions.\n","After delete new items in test data, test data has 8352 interactions.\n","The number of total unseen interactions is 32.\n","Generate eposide data for training.\n","Generate eposide data for validation.\n","Generate eposide data for testing.\n","Preprocess is done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LcVm-jbX2DY","executionInfo":{"status":"ok","timestamp":1635852001756,"user_tz":-330,"elapsed":629,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"41cf96af-8acd-48b3-fe86-f97f4e285df1"},"source":["print(\"Create model TaNP...\")\n","\n","opt['uf_dim'] = preprocess.uf_dim\n","opt['if_dim'] = preprocess.if_dim\n","\n","trainer = Trainer(opt)\n","\n","if opt['use_cuda']:\n","    trainer.cuda()\n","\n","model_filename = \"{}/{}.pt\".format(opt['model_save_dir'], opt[\"id\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Create model TaNP...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akwldBc9YI6G","executionInfo":{"status":"ok","timestamp":1635852007273,"user_tz":-330,"elapsed":1811,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"653f6042-f6f8-4647-87d5-0c24fd303157"},"source":["# /4 since sup_x, sup_y, query_x, query_y\n","training_set_size = int(len(os.listdir(\"{}/{}/{}\".format(opt[\"data_dir\"], \"training\", \"log\"))) / 4)\n","supp_xs_s = []\n","supp_ys_s = []\n","query_xs_s = []\n","query_ys_s = []\n","\n","for idx in range(training_set_size):\n","    supp_xs_s.append(pickle.load(open(\"{}/{}/{}/supp_x_{}.pkl\".format(opt[\"data_dir\"], \"training\", \"log\", idx), \"rb\")))\n","    supp_ys_s.append(pickle.load(open(\"{}/{}/{}/supp_y_{}.pkl\".format(opt[\"data_dir\"], \"training\", \"log\", idx), \"rb\")))\n","    query_xs_s.append(pickle.load(open(\"{}/{}/{}/query_x_{}.pkl\".format(opt[\"data_dir\"], \"training\", \"log\", idx), \"rb\")))\n","    query_ys_s.append(pickle.load(open(\"{}/{}/{}/query_y_{}.pkl\".format(opt[\"data_dir\"], \"training\", \"log\", idx), \"rb\")))\n","\n","train_dataset = list(zip(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s))\n","\n","del (supp_xs_s, supp_ys_s, query_xs_s, query_ys_s)\n","\n","testing_set_size = int(len(os.listdir(\"{}/{}/{}\".format(opt[\"data_dir\"], \"testing\", \"log\"))) / 4)\n","supp_xs_s = []\n","supp_ys_s = []\n","query_xs_s = []\n","query_ys_s = []\n","\n","for idx in range(testing_set_size):\n","    supp_xs_s.append(\n","        pickle.load(open(\"{}/{}/{}/supp_x_{}.pkl\".format(opt[\"data_dir\"], \"testing\", \"log\", idx), \"rb\")))\n","    supp_ys_s.append(\n","        pickle.load(open(\"{}/{}/{}/supp_y_{}.pkl\".format(opt[\"data_dir\"], \"testing\", \"log\", idx), \"rb\")))\n","    query_xs_s.append(\n","        pickle.load(open(\"{}/{}/{}/query_x_{}.pkl\".format(opt[\"data_dir\"], \"testing\", \"log\", idx), \"rb\")))\n","    query_ys_s.append(\n","        pickle.load(open(\"{}/{}/{}/query_y_{}.pkl\".format(opt[\"data_dir\"], \"testing\", \"log\", idx), \"rb\")))\n","    \n","test_dataset = list(zip(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s))\n","\n","del (supp_xs_s, supp_ys_s, query_xs_s, query_ys_s)\n","\n","print(\"# epoch\\ttrain_loss\\tprecision5\\tNDCG5\\tMAP5\\tprecision7\\tNDCG7\\tMAP7\\tprecision10\\tNDCG10\\tMAP10\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# epoch\ttrain_loss\tprecision5\tNDCG5\tMAP5\tprecision7\tNDCG7\tMAP7\tprecision10\tNDCG10\tMAP10\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B250JVLpYHZg","executionInfo":{"status":"ok","timestamp":1635852355637,"user_tz":-330,"elapsed":335740,"user":{"displayName":"Sparsh Agarwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13037694610922482904"}},"outputId":"df0b37ad-6ec8-4fcd-97f6-28bbf010c763"},"source":["if not os.path.exists(model_filename):\n","    print(\"Start training...\")\n","    training(trainer, opt, train_dataset, test_dataset, batch_size=opt['batch_size'], num_epoch=opt['num_epoch'],\n","            model_save=opt[\"save\"], model_filename=model_filename, logger=file_logger)\n","\n","else:\n","    print(\"Load pre-trained model...\")\n","    opt = helper.load_config(model_filename[:-2]+\"config\")\n","    helper.print_config(opt)\n","    trained_state_dict = torch.load(model_filename)\n","    trainer.load_state_dict(trained_state_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start training...\n","0\t1.856907\t TOP-5 0.5182\t0.4987\t0.4012\t TOP-7: 0.6190\t0.5343\t0.5179\t TOP-10: 0.8030\t0.6329\t0.7485\n","1\t1.837023\t TOP-5 0.5091\t0.4801\t0.3818\t TOP-7: 0.6212\t0.5263\t0.5183\t TOP-10: 0.7939\t0.6147\t0.7400\n","2\t1.818658\t TOP-5 0.5242\t0.4947\t0.3975\t TOP-7: 0.6299\t0.5347\t0.5318\t TOP-10: 0.7985\t0.6228\t0.7514\n","3\t1.791948\t TOP-5 0.4970\t0.4809\t0.3767\t TOP-7: 0.6082\t0.5217\t0.5108\t TOP-10: 0.7939\t0.6191\t0.7437\n","4\t1.775398\t TOP-5 0.4818\t0.4545\t0.3560\t TOP-7: 0.6104\t0.5087\t0.5027\t TOP-10: 0.7939\t0.6059\t0.7472\n","5\t1.762931\t TOP-5 0.5212\t0.4968\t0.3906\t TOP-7: 0.6277\t0.5378\t0.5180\t TOP-10: 0.7955\t0.6262\t0.7453\n","6\t1.733476\t TOP-5 0.5333\t0.5010\t0.3951\t TOP-7: 0.6234\t0.5304\t0.5235\t TOP-10: 0.8030\t0.6239\t0.7563\n","7\t1.713983\t TOP-5 0.4939\t0.4781\t0.3739\t TOP-7: 0.6169\t0.5306\t0.5095\t TOP-10: 0.7924\t0.6236\t0.7406\n","8\t1.694841\t TOP-5 0.4939\t0.4639\t0.3480\t TOP-7: 0.6082\t0.5101\t0.4925\t TOP-10: 0.7894\t0.6051\t0.7315\n","9\t1.679368\t TOP-5 0.4909\t0.4595\t0.3587\t TOP-7: 0.6061\t0.5026\t0.4971\t TOP-10: 0.7879\t0.5973\t0.7333\n","10\t1.650621\t TOP-5 0.5030\t0.4903\t0.3868\t TOP-7: 0.5866\t0.5087\t0.4968\t TOP-10: 0.7894\t0.6180\t0.7351\n","11\t1.640563\t TOP-5 0.5061\t0.5078\t0.4051\t TOP-7: 0.6017\t0.5328\t0.5148\t TOP-10: 0.7970\t0.6378\t0.7486\n","12\t1.627022\t TOP-5 0.5182\t0.5047\t0.4028\t TOP-7: 0.6299\t0.5465\t0.5292\t TOP-10: 0.7924\t0.6281\t0.7447\n","13\t1.617046\t TOP-5 0.5394\t0.5362\t0.4354\t TOP-7: 0.6255\t0.5599\t0.5403\t TOP-10: 0.7985\t0.6491\t0.7505\n","14\t1.613055\t TOP-5 0.5394\t0.5351\t0.4466\t TOP-7: 0.6212\t0.5562\t0.5404\t TOP-10: 0.7970\t0.6457\t0.7469\n","15\t1.612253\t TOP-5 0.5394\t0.5370\t0.4405\t TOP-7: 0.6429\t0.5728\t0.5555\t TOP-10: 0.8000\t0.6516\t0.7547\n","16\t1.613116\t TOP-5 0.5485\t0.5417\t0.4530\t TOP-7: 0.6429\t0.5699\t0.5576\t TOP-10: 0.8091\t0.6575\t0.7611\n","17\t1.612329\t TOP-5 0.5576\t0.5600\t0.4641\t TOP-7: 0.6515\t0.5912\t0.5674\t TOP-10: 0.8030\t0.6657\t0.7572\n","18\t1.612467\t TOP-5 0.5576\t0.5610\t0.4598\t TOP-7: 0.6407\t0.5844\t0.5617\t TOP-10: 0.8167\t0.6786\t0.7683\n","19\t1.612230\t TOP-5 0.5515\t0.5497\t0.4414\t TOP-7: 0.6407\t0.5791\t0.5548\t TOP-10: 0.8045\t0.6624\t0.7570\n","20\t1.612224\t TOP-5 0.5697\t0.5723\t0.4718\t TOP-7: 0.6407\t0.5874\t0.5588\t TOP-10: 0.8076\t0.6736\t0.7634\n","21\t1.612313\t TOP-5 0.5455\t0.5573\t0.4510\t TOP-7: 0.6472\t0.5913\t0.5633\t TOP-10: 0.7985\t0.6645\t0.7520\n","22\t1.612323\t TOP-5 0.5485\t0.5448\t0.4440\t TOP-7: 0.6429\t0.5770\t0.5562\t TOP-10: 0.8061\t0.6610\t0.7571\n","23\t1.612233\t TOP-5 0.5788\t0.5699\t0.4704\t TOP-7: 0.6558\t0.5905\t0.5668\t TOP-10: 0.8167\t0.6751\t0.7727\n","24\t1.612160\t TOP-5 0.5667\t0.5725\t0.4790\t TOP-7: 0.6407\t0.5886\t0.5616\t TOP-10: 0.8227\t0.6890\t0.7765\n","25\t1.612278\t TOP-5 0.5515\t0.5529\t0.4595\t TOP-7: 0.6385\t0.5773\t0.5606\t TOP-10: 0.8061\t0.6625\t0.7599\n","26\t1.612371\t TOP-5 0.5818\t0.5853\t0.4892\t TOP-7: 0.6342\t0.5884\t0.5645\t TOP-10: 0.8091\t0.6801\t0.7655\n","27\t1.612172\t TOP-5 0.5697\t0.5674\t0.4743\t TOP-7: 0.6537\t0.5932\t0.5717\t TOP-10: 0.8167\t0.6788\t0.7705\n","28\t1.612243\t TOP-5 0.5788\t0.5821\t0.4817\t TOP-7: 0.6537\t0.6017\t0.5716\t TOP-10: 0.8152\t0.6857\t0.7715\n","29\t1.612235\t TOP-5 0.5879\t0.5848\t0.4862\t TOP-7: 0.6710\t0.6112\t0.5895\t TOP-10: 0.8152\t0.6831\t0.7719\n","30\t1.612229\t TOP-5 0.5697\t0.5727\t0.4736\t TOP-7: 0.6602\t0.6010\t0.5739\t TOP-10: 0.8121\t0.6794\t0.7695\n","31\t1.612226\t TOP-5 0.5970\t0.5962\t0.5053\t TOP-7: 0.6515\t0.6009\t0.5781\t TOP-10: 0.8106\t0.6836\t0.7712\n","32\t1.612235\t TOP-5 0.6091\t0.6046\t0.5053\t TOP-7: 0.6623\t0.6099\t0.5878\t TOP-10: 0.8242\t0.6976\t0.7819\n","33\t1.612212\t TOP-5 0.6061\t0.6010\t0.5144\t TOP-7: 0.6710\t0.6141\t0.5952\t TOP-10: 0.8167\t0.6885\t0.7779\n","34\t1.612112\t TOP-5 0.5909\t0.5952\t0.4988\t TOP-7: 0.6688\t0.6166\t0.5966\t TOP-10: 0.8273\t0.7019\t0.7836\n","35\t1.612202\t TOP-5 0.5970\t0.6018\t0.5118\t TOP-7: 0.6732\t0.6229\t0.6024\t TOP-10: 0.8212\t0.6981\t0.7809\n","36\t1.612195\t TOP-5 0.6030\t0.6049\t0.5188\t TOP-7: 0.6667\t0.6163\t0.5949\t TOP-10: 0.8167\t0.6929\t0.7785\n","37\t1.612210\t TOP-5 0.5818\t0.5881\t0.5002\t TOP-7: 0.6861\t0.6279\t0.6114\t TOP-10: 0.8273\t0.7016\t0.7880\n","38\t1.612166\t TOP-5 0.6091\t0.6128\t0.5204\t TOP-7: 0.6883\t0.6361\t0.6150\t TOP-10: 0.8288\t0.7090\t0.7920\n","39\t1.612114\t TOP-5 0.6121\t0.6109\t0.5176\t TOP-7: 0.6775\t0.6247\t0.6010\t TOP-10: 0.8258\t0.7021\t0.7854\n","40\t1.612206\t TOP-5 0.6333\t0.6283\t0.5447\t TOP-7: 0.6926\t0.6403\t0.6210\t TOP-10: 0.8364\t0.7161\t0.7960\n","41\t1.612156\t TOP-5 0.6152\t0.6213\t0.5299\t TOP-7: 0.6883\t0.6413\t0.6163\t TOP-10: 0.8394\t0.7245\t0.8006\n","42\t1.612199\t TOP-5 0.6152\t0.6164\t0.5296\t TOP-7: 0.6926\t0.6409\t0.6167\t TOP-10: 0.8288\t0.7102\t0.7918\n","43\t1.612141\t TOP-5 0.6333\t0.6322\t0.5404\t TOP-7: 0.6991\t0.6478\t0.6292\t TOP-10: 0.8379\t0.7209\t0.7999\n","44\t1.612143\t TOP-5 0.6212\t0.6242\t0.5334\t TOP-7: 0.7078\t0.6558\t0.6322\t TOP-10: 0.8439\t0.7273\t0.8066\n","45\t1.612111\t TOP-5 0.6333\t0.6388\t0.5510\t TOP-7: 0.7035\t0.6576\t0.6348\t TOP-10: 0.8409\t0.7297\t0.8043\n","46\t1.612049\t TOP-5 0.6303\t0.6394\t0.5489\t TOP-7: 0.7078\t0.6628\t0.6432\t TOP-10: 0.8439\t0.7331\t0.8074\n","47\t1.612166\t TOP-5 0.6394\t0.6386\t0.5500\t TOP-7: 0.7165\t0.6641\t0.6441\t TOP-10: 0.8364\t0.7245\t0.7994\n","48\t1.612162\t TOP-5 0.6333\t0.6355\t0.5443\t TOP-7: 0.7121\t0.6616\t0.6367\t TOP-10: 0.8394\t0.7270\t0.8020\n","49\t1.612158\t TOP-5 0.6364\t0.6439\t0.5566\t TOP-7: 0.7143\t0.6696\t0.6459\t TOP-10: 0.8318\t0.7275\t0.7974\n","50\t1.612147\t TOP-5 0.6455\t0.6488\t0.5611\t TOP-7: 0.6991\t0.6589\t0.6382\t TOP-10: 0.8394\t0.7320\t0.8050\n","51\t1.612150\t TOP-5 0.6545\t0.6562\t0.5724\t TOP-7: 0.7229\t0.6768\t0.6564\t TOP-10: 0.8394\t0.7344\t0.8060\n","52\t1.612108\t TOP-5 0.6515\t0.6605\t0.5737\t TOP-7: 0.7078\t0.6720\t0.6473\t TOP-10: 0.8455\t0.7433\t0.8104\n","53\t1.612151\t TOP-5 0.6667\t0.6614\t0.5781\t TOP-7: 0.7165\t0.6702\t0.6506\t TOP-10: 0.8394\t0.7312\t0.8047\n","54\t1.612093\t TOP-5 0.6485\t0.6550\t0.5629\t TOP-7: 0.7078\t0.6690\t0.6422\t TOP-10: 0.8470\t0.7427\t0.8100\n","55\t1.612118\t TOP-5 0.6515\t0.6564\t0.5676\t TOP-7: 0.7121\t0.6701\t0.6444\t TOP-10: 0.8409\t0.7379\t0.8043\n","56\t1.612094\t TOP-5 0.6758\t0.6830\t0.5956\t TOP-7: 0.7165\t0.6849\t0.6605\t TOP-10: 0.8515\t0.7556\t0.8186\n","57\t1.612080\t TOP-5 0.6545\t0.6583\t0.5745\t TOP-7: 0.7186\t0.6755\t0.6551\t TOP-10: 0.8561\t0.7496\t0.8201\n","58\t1.612107\t TOP-5 0.6758\t0.6803\t0.5969\t TOP-7: 0.7143\t0.6799\t0.6573\t TOP-10: 0.8485\t0.7510\t0.8151\n","59\t1.612218\t TOP-5 0.6788\t0.6767\t0.5906\t TOP-7: 0.7208\t0.6804\t0.6571\t TOP-10: 0.8500\t0.7483\t0.8165\n","60\t1.612088\t TOP-5 0.6758\t0.6804\t0.5963\t TOP-7: 0.7229\t0.6866\t0.6654\t TOP-10: 0.8545\t0.7559\t0.8211\n","61\t1.612147\t TOP-5 0.6697\t0.6724\t0.5879\t TOP-7: 0.7273\t0.6863\t0.6636\t TOP-10: 0.8530\t0.7516\t0.8185\n","62\t1.612061\t TOP-5 0.6606\t0.6694\t0.5876\t TOP-7: 0.7165\t0.6809\t0.6547\t TOP-10: 0.8561\t0.7563\t0.8221\n","63\t1.612108\t TOP-5 0.6848\t0.6892\t0.6077\t TOP-7: 0.7229\t0.6892\t0.6633\t TOP-10: 0.8636\t0.7668\t0.8286\n","64\t1.612122\t TOP-5 0.6818\t0.6831\t0.5975\t TOP-7: 0.7294\t0.6909\t0.6655\t TOP-10: 0.8576\t0.7601\t0.8250\n","65\t1.612101\t TOP-5 0.6727\t0.6778\t0.5936\t TOP-7: 0.7316\t0.6932\t0.6714\t TOP-10: 0.8530\t0.7565\t0.8218\n","66\t1.612128\t TOP-5 0.6788\t0.6815\t0.5985\t TOP-7: 0.7316\t0.6922\t0.6704\t TOP-10: 0.8606\t0.7610\t0.8287\n","67\t1.612063\t TOP-5 0.6788\t0.6788\t0.5984\t TOP-7: 0.7229\t0.6837\t0.6647\t TOP-10: 0.8515\t0.7524\t0.8202\n","68\t1.612064\t TOP-5 0.6818\t0.6866\t0.6061\t TOP-7: 0.7338\t0.6966\t0.6736\t TOP-10: 0.8561\t0.7614\t0.8266\n","69\t1.612055\t TOP-5 0.6818\t0.6857\t0.6053\t TOP-7: 0.7359\t0.6973\t0.6762\t TOP-10: 0.8606\t0.7643\t0.8300\n","70\t1.612084\t TOP-5 0.6818\t0.6887\t0.6073\t TOP-7: 0.7338\t0.6974\t0.6759\t TOP-10: 0.8561\t0.7624\t0.8257\n","71\t1.612110\t TOP-5 0.6879\t0.6958\t0.6161\t TOP-7: 0.7446\t0.7087\t0.6881\t TOP-10: 0.8561\t0.7675\t0.8264\n","72\t1.612086\t TOP-5 0.6848\t0.6901\t0.6089\t TOP-7: 0.7403\t0.7032\t0.6795\t TOP-10: 0.8545\t0.7626\t0.8248\n","73\t1.612070\t TOP-5 0.6939\t0.6983\t0.6164\t TOP-7: 0.7359\t0.7022\t0.6799\t TOP-10: 0.8606\t0.7697\t0.8307\n","74\t1.612030\t TOP-5 0.7000\t0.7037\t0.6218\t TOP-7: 0.7468\t0.7116\t0.6894\t TOP-10: 0.8591\t0.7704\t0.8288\n","75\t1.612020\t TOP-5 0.6939\t0.6985\t0.6207\t TOP-7: 0.7424\t0.7066\t0.6868\t TOP-10: 0.8545\t0.7644\t0.8242\n","76\t1.612044\t TOP-5 0.6818\t0.6945\t0.6124\t TOP-7: 0.7446\t0.7110\t0.6859\t TOP-10: 0.8576\t0.7697\t0.8286\n","77\t1.612071\t TOP-5 0.7030\t0.7068\t0.6229\t TOP-7: 0.7511\t0.7161\t0.6897\t TOP-10: 0.8561\t0.7691\t0.8270\n","78\t1.612004\t TOP-5 0.6909\t0.6968\t0.6120\t TOP-7: 0.7468\t0.7104\t0.6864\t TOP-10: 0.8606\t0.7695\t0.8303\n","79\t1.612048\t TOP-5 0.6939\t0.7009\t0.6176\t TOP-7: 0.7489\t0.7138\t0.6887\t TOP-10: 0.8530\t0.7667\t0.8248\n","80\t1.612098\t TOP-5 0.6909\t0.6992\t0.6178\t TOP-7: 0.7446\t0.7112\t0.6888\t TOP-10: 0.8621\t0.7736\t0.8313\n","81\t1.612056\t TOP-5 0.7061\t0.7106\t0.6255\t TOP-7: 0.7381\t0.7092\t0.6824\t TOP-10: 0.8576\t0.7719\t0.8285\n","82\t1.612006\t TOP-5 0.6970\t0.7048\t0.6205\t TOP-7: 0.7424\t0.7118\t0.6839\t TOP-10: 0.8576\t0.7710\t0.8283\n","83\t1.612046\t TOP-5 0.7000\t0.7098\t0.6270\t TOP-7: 0.7381\t0.7113\t0.6817\t TOP-10: 0.8606\t0.7758\t0.8300\n","84\t1.612011\t TOP-5 0.6970\t0.7057\t0.6195\t TOP-7: 0.7359\t0.7082\t0.6782\t TOP-10: 0.8591\t0.7742\t0.8300\n","85\t1.612089\t TOP-5 0.6939\t0.7072\t0.6214\t TOP-7: 0.7424\t0.7148\t0.6856\t TOP-10: 0.8591\t0.7764\t0.8318\n","86\t1.612003\t TOP-5 0.6879\t0.7018\t0.6169\t TOP-7: 0.7381\t0.7108\t0.6838\t TOP-10: 0.8591\t0.7743\t0.8295\n","87\t1.612035\t TOP-5 0.6909\t0.7024\t0.6231\t TOP-7: 0.7424\t0.7118\t0.6862\t TOP-10: 0.8606\t0.7740\t0.8315\n","88\t1.612017\t TOP-5 0.7030\t0.7080\t0.6272\t TOP-7: 0.7532\t0.7182\t0.6963\t TOP-10: 0.8606\t0.7736\t0.8325\n","89\t1.612063\t TOP-5 0.7061\t0.7161\t0.6340\t TOP-7: 0.7446\t0.7180\t0.6918\t TOP-10: 0.8606\t0.7790\t0.8316\n","90\t1.612056\t TOP-5 0.7030\t0.7098\t0.6292\t TOP-7: 0.7511\t0.7188\t0.6954\t TOP-10: 0.8576\t0.7728\t0.8291\n","91\t1.612038\t TOP-5 0.7182\t0.7244\t0.6428\t TOP-7: 0.7576\t0.7279\t0.7034\t TOP-10: 0.8591\t0.7792\t0.8324\n","92\t1.612083\t TOP-5 0.7000\t0.7140\t0.6324\t TOP-7: 0.7532\t0.7258\t0.6986\t TOP-10: 0.8621\t0.7831\t0.8345\n","93\t1.612014\t TOP-5 0.7091\t0.7168\t0.6393\t TOP-7: 0.7511\t0.7219\t0.6973\t TOP-10: 0.8636\t0.7813\t0.8333\n","94\t1.612027\t TOP-5 0.7030\t0.7131\t0.6327\t TOP-7: 0.7641\t0.7311\t0.7078\t TOP-10: 0.8621\t0.7805\t0.8335\n","95\t1.612071\t TOP-5 0.7061\t0.7156\t0.6364\t TOP-7: 0.7576\t0.7268\t0.7047\t TOP-10: 0.8636\t0.7820\t0.8350\n","96\t1.612094\t TOP-5 0.7182\t0.7241\t0.6460\t TOP-7: 0.7532\t0.7255\t0.7020\t TOP-10: 0.8621\t0.7820\t0.8329\n","97\t1.612068\t TOP-5 0.7121\t0.7215\t0.6470\t TOP-7: 0.7576\t0.7294\t0.7043\t TOP-10: 0.8636\t0.7842\t0.8350\n","98\t1.612072\t TOP-5 0.7182\t0.7245\t0.6498\t TOP-7: 0.7489\t0.7219\t0.6994\t TOP-10: 0.8621\t0.7804\t0.8339\n","99\t1.612078\t TOP-5 0.7182\t0.7255\t0.6489\t TOP-7: 0.7532\t0.7259\t0.7027\t TOP-10: 0.8667\t0.7862\t0.8375\n","100\t1.612096\t TOP-5 0.7091\t0.7193\t0.6441\t TOP-7: 0.7576\t0.7279\t0.7058\t TOP-10: 0.8636\t0.7822\t0.8354\n","101\t1.612080\t TOP-5 0.7121\t0.7239\t0.6489\t TOP-7: 0.7554\t0.7298\t0.7057\t TOP-10: 0.8636\t0.7840\t0.8346\n","102\t1.612069\t TOP-5 0.7182\t0.7282\t0.6529\t TOP-7: 0.7511\t0.7272\t0.7026\t TOP-10: 0.8606\t0.7820\t0.8318\n","103\t1.611941\t TOP-5 0.7121\t0.7212\t0.6476\t TOP-7: 0.7489\t0.7227\t0.7001\t TOP-10: 0.8576\t0.7773\t0.8290\n","104\t1.612042\t TOP-5 0.7091\t0.7211\t0.6466\t TOP-7: 0.7468\t0.7226\t0.6998\t TOP-10: 0.8652\t0.7851\t0.8354\n","105\t1.612058\t TOP-5 0.7152\t0.7262\t0.6494\t TOP-7: 0.7446\t0.7218\t0.7000\t TOP-10: 0.8636\t0.7845\t0.8339\n","106\t1.612054\t TOP-5 0.7182\t0.7333\t0.6577\t TOP-7: 0.7468\t0.7281\t0.7036\t TOP-10: 0.8667\t0.7918\t0.8381\n","107\t1.612006\t TOP-5 0.7212\t0.7343\t0.6588\t TOP-7: 0.7532\t0.7323\t0.7082\t TOP-10: 0.8652\t0.7907\t0.8365\n","108\t1.612074\t TOP-5 0.7273\t0.7365\t0.6601\t TOP-7: 0.7554\t0.7325\t0.7102\t TOP-10: 0.8652\t0.7895\t0.8367\n","109\t1.612030\t TOP-5 0.7242\t0.7356\t0.6587\t TOP-7: 0.7511\t0.7298\t0.7072\t TOP-10: 0.8621\t0.7874\t0.8338\n","110\t1.612028\t TOP-5 0.7212\t0.7341\t0.6595\t TOP-7: 0.7511\t0.7306\t0.7070\t TOP-10: 0.8652\t0.7904\t0.8363\n","111\t1.611958\t TOP-5 0.7212\t0.7339\t0.6583\t TOP-7: 0.7489\t0.7291\t0.7059\t TOP-10: 0.8621\t0.7881\t0.8342\n","112\t1.611995\t TOP-5 0.7212\t0.7323\t0.6559\t TOP-7: 0.7489\t0.7280\t0.7032\t TOP-10: 0.8652\t0.7894\t0.8362\n","113\t1.611984\t TOP-5 0.7242\t0.7333\t0.6585\t TOP-7: 0.7489\t0.7271\t0.7044\t TOP-10: 0.8606\t0.7855\t0.8333\n","114\t1.612095\t TOP-5 0.7242\t0.7349\t0.6597\t TOP-7: 0.7446\t0.7261\t0.7008\t TOP-10: 0.8621\t0.7881\t0.8343\n","115\t1.611942\t TOP-5 0.7273\t0.7390\t0.6638\t TOP-7: 0.7446\t0.7275\t0.7020\t TOP-10: 0.8636\t0.7903\t0.8345\n","116\t1.611989\t TOP-5 0.7273\t0.7384\t0.6639\t TOP-7: 0.7468\t0.7286\t0.7057\t TOP-10: 0.8636\t0.7905\t0.8346\n","117\t1.612036\t TOP-5 0.7333\t0.7415\t0.6686\t TOP-7: 0.7468\t0.7280\t0.7048\t TOP-10: 0.8652\t0.7912\t0.8370\n","118\t1.611936\t TOP-5 0.7242\t0.7394\t0.6679\t TOP-7: 0.7489\t0.7322\t0.7075\t TOP-10: 0.8636\t0.7931\t0.8353\n","119\t1.611901\t TOP-5 0.7303\t0.7431\t0.6703\t TOP-7: 0.7489\t0.7321\t0.7082\t TOP-10: 0.8682\t0.7961\t0.8380\n","120\t1.611992\t TOP-5 0.7273\t0.7422\t0.6696\t TOP-7: 0.7489\t0.7330\t0.7076\t TOP-10: 0.8621\t0.7930\t0.8344\n","121\t1.611983\t TOP-5 0.7303\t0.7470\t0.6741\t TOP-7: 0.7576\t0.7414\t0.7164\t TOP-10: 0.8621\t0.7971\t0.8355\n","122\t1.612123\t TOP-5 0.7333\t0.7489\t0.6766\t TOP-7: 0.7576\t0.7415\t0.7151\t TOP-10: 0.8682\t0.8013\t0.8404\n","123\t1.612018\t TOP-5 0.7273\t0.7447\t0.6710\t TOP-7: 0.7554\t0.7400\t0.7125\t TOP-10: 0.8682\t0.8014\t0.8401\n","124\t1.611930\t TOP-5 0.7303\t0.7456\t0.6722\t TOP-7: 0.7576\t0.7407\t0.7149\t TOP-10: 0.8667\t0.7997\t0.8391\n","125\t1.612020\t TOP-5 0.7273\t0.7435\t0.6694\t TOP-7: 0.7597\t0.7419\t0.7153\t TOP-10: 0.8697\t0.8016\t0.8417\n","126\t1.611896\t TOP-5 0.7273\t0.7445\t0.6707\t TOP-7: 0.7597\t0.7428\t0.7160\t TOP-10: 0.8682\t0.8015\t0.8412\n","127\t1.611954\t TOP-5 0.7303\t0.7476\t0.6737\t TOP-7: 0.7641\t0.7463\t0.7214\t TOP-10: 0.8697\t0.8031\t0.8429\n","128\t1.611978\t TOP-5 0.7333\t0.7511\t0.6786\t TOP-7: 0.7706\t0.7518\t0.7264\t TOP-10: 0.8697\t0.8043\t0.8435\n","129\t1.611915\t TOP-5 0.7333\t0.7517\t0.6794\t TOP-7: 0.7706\t0.7523\t0.7267\t TOP-10: 0.8712\t0.8058\t0.8447\n","130\t1.611929\t TOP-5 0.7303\t0.7499\t0.6761\t TOP-7: 0.7706\t0.7528\t0.7261\t TOP-10: 0.8727\t0.8067\t0.8456\n","131\t1.611872\t TOP-5 0.7303\t0.7494\t0.6754\t TOP-7: 0.7727\t0.7538\t0.7262\t TOP-10: 0.8742\t0.8076\t0.8474\n","132\t1.612004\t TOP-5 0.7303\t0.7492\t0.6737\t TOP-7: 0.7706\t0.7525\t0.7257\t TOP-10: 0.8773\t0.8101\t0.8503\n","133\t1.612010\t TOP-5 0.7333\t0.7517\t0.6757\t TOP-7: 0.7749\t0.7570\t0.7300\t TOP-10: 0.8758\t0.8097\t0.8487\n","134\t1.611947\t TOP-5 0.7364\t0.7508\t0.6764\t TOP-7: 0.7727\t0.7519\t0.7286\t TOP-10: 0.8758\t0.8067\t0.8491\n","135\t1.611911\t TOP-5 0.7333\t0.7508\t0.6735\t TOP-7: 0.7771\t0.7575\t0.7303\t TOP-10: 0.8727\t0.8067\t0.8468\n","136\t1.611733\t TOP-5 0.7364\t0.7510\t0.6766\t TOP-7: 0.7771\t0.7562\t0.7322\t TOP-10: 0.8742\t0.8066\t0.8484\n","137\t1.612025\t TOP-5 0.7394\t0.7533\t0.6796\t TOP-7: 0.7835\t0.7625\t0.7385\t TOP-10: 0.8742\t0.8072\t0.8481\n","138\t1.611871\t TOP-5 0.7455\t0.7562\t0.6843\t TOP-7: 0.7814\t0.7602\t0.7375\t TOP-10: 0.8758\t0.8074\t0.8486\n","139\t1.611889\t TOP-5 0.7424\t0.7542\t0.6819\t TOP-7: 0.7771\t0.7574\t0.7335\t TOP-10: 0.8773\t0.8080\t0.8497\n","140\t1.611859\t TOP-5 0.7364\t0.7506\t0.6783\t TOP-7: 0.7792\t0.7591\t0.7348\t TOP-10: 0.8773\t0.8086\t0.8501\n","141\t1.612003\t TOP-5 0.7333\t0.7493\t0.6765\t TOP-7: 0.7749\t0.7566\t0.7321\t TOP-10: 0.8788\t0.8113\t0.8519\n","142\t1.611754\t TOP-5 0.7424\t0.7543\t0.6828\t TOP-7: 0.7771\t0.7584\t0.7342\t TOP-10: 0.8803\t0.8121\t0.8534\n","143\t1.611885\t TOP-5 0.7485\t0.7584\t0.6887\t TOP-7: 0.7771\t0.7577\t0.7347\t TOP-10: 0.8818\t0.8137\t0.8554\n","144\t1.611870\t TOP-5 0.7576\t0.7660\t0.6967\t TOP-7: 0.7771\t0.7587\t0.7348\t TOP-10: 0.8864\t0.8183\t0.8596\n","145\t1.611834\t TOP-5 0.7545\t0.7632\t0.6927\t TOP-7: 0.7792\t0.7596\t0.7361\t TOP-10: 0.8879\t0.8180\t0.8609\n","146\t1.611955\t TOP-5 0.7485\t0.7595\t0.6884\t TOP-7: 0.7814\t0.7610\t0.7371\t TOP-10: 0.8879\t0.8181\t0.8610\n","147\t1.611880\t TOP-5 0.7485\t0.7612\t0.6874\t TOP-7: 0.7814\t0.7629\t0.7377\t TOP-10: 0.8879\t0.8200\t0.8612\n","148\t1.611771\t TOP-5 0.7515\t0.7644\t0.6899\t TOP-7: 0.7835\t0.7664\t0.7407\t TOP-10: 0.8879\t0.8221\t0.8612\n","149\t1.611839\t TOP-5 0.7455\t0.7613\t0.6851\t TOP-7: 0.7835\t0.7671\t0.7400\t TOP-10: 0.8879\t0.8227\t0.8616\n"]}]},{"cell_type":"markdown","metadata":{"id":"iXB7KEkLYOXQ"},"source":["**END**"]}]}