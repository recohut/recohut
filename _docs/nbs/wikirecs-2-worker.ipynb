{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wikirecs-2.worker","provenance":[{"file_id":"1oar0IIoKvzlao9331q0pCluMvDwhaJh4","timestamp":1625764091799},{"file_id":"1KDUlGmiF0QDqDEriKYiAn9i5Xhxtpy10","timestamp":1625763528590}],"collapsed_sections":[],"mount_file_id":"1Gr4GCAcjI5y_Uo25c39zxnomGW01xxJH","authorship_tag":"ABX9TyNWkzgXCagKOfC4jrJmIdw4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Jep4VQyz3ZzE"},"source":["project_name=\"reco-wikirecs\"; branch=\"master\"; account=\"sparsh-ai\"\n","\n","!cp /content/drive/MyDrive/mykeys.py /content\n","import mykeys\n","!rm /content/mykeys.py\n","path = \"/content/\" + project_name; \n","!mkdir \"{path}\"\n","%cd \"{path}\"\n","import sys; sys.path.append(path)\n","!git config --global user.email \"sparsh@recohut.com\"\n","!git config --global user.name  \"colab-sparsh\"\n","!git init\n","!git remote add origin https://\"{mykeys.git_token}\":x-oauth-basic@github.com/\"{account}\"/\"{project_name}\".git\n","!git pull origin \"{branch}\"\n","\n","# !git status\n","# !git add . && git commit -m 'commit' && git push origin \"{branch}\"\n","\n","!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPv3P678HCYi","executionInfo":{"status":"ok","timestamp":1625764422021,"user_tz":-330,"elapsed":776,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"7c9cd3ea-a618-440f-de9c-50e127050317"},"source":["%cd /content/reco-wikirecs"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/reco-wikirecs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c_uAz5OS4sm3","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1625764425239,"user_tz":-330,"elapsed":531,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"0b55e16c-e93f-4e14-80c0-bee9d54f3b2e"},"source":["import yaml\n","import os\n","from itables.javascript import load_datatables\n","load_datatables()\n","\n","with open('config.yaml') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/javascript":["require.config({\n","    paths: {\n","        datatables: 'https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min',\n","    }\n","});\n","\n","$('head').append('<link rel=\"stylesheet\" type=\"text/css\" \\\n","                href = \"https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\" > ');\n","\n","$('head').append('<style> table td { text-overflow: ellipsis; overflow: hidden; } </style>');\n","\n","$('head').append(`<script>\n","function eval_functions(map_or_text) {\n","    if (typeof map_or_text === \"string\") {\n","        if (map_or_text.startsWith(\"function\")) {\n","            try {\n","                // Note: parenthesis are required around the whole expression for eval to return a value!\n","                // See https://stackoverflow.com/a/7399078/911298.\n","                //\n","                // eval(\"local_fun = \" + map_or_text) would fail because local_fun is not declared\n","                // (using var, let or const would work, but it would only be declared in the local scope\n","                // and therefore the value could not be retrieved).\n","                const func = eval(\"(\" + map_or_text + \")\");\n","                if (typeof func !== \"function\") {\n","                    // Note: backquotes are super convenient!\n","                    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\n","                    console.error(\"Evaluated expression \" + map_or_text + \" is not a function (type is \" + typeof func + \")\");\n","                    return map_or_text;\n","                }\n","                // Return the function\n","                return func;\n","            } catch (e) {\n","                // Make sure to print the error with a second argument to console.error().\n","                console.error(\"itables was not able to parse \" + map_or_text, e);\n","            }\n","        }\n","    } else if (typeof map_or_text === \"object\") {\n","        if (map_or_text instanceof Array) {\n","            // Note: \"var\" is now superseded by \"let\" and \"const\".\n","            // https://medium.com/javascript-scene/javascript-es6-var-let-or-const-ba58b8dcde75\n","            const result = [];\n","            // Note: \"for of\" is the best way to iterate through an iterable.\n","            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for...of\n","            for (const item of map_or_text) {\n","                result.push(eval_functions(item));\n","            }\n","            return result;\n","\n","            // Alternatively, more functional approach in one line:\n","            // return map_or_text.map(eval_functions);\n","        } else {\n","            const result = {};\n","            // Object.keys() is safer than \"for in\" because otherwise you might have keys\n","            // that aren't defined in the object itself.\n","            //\n","            // See https://stackoverflow.com/a/684692/911298.\n","            for (const item of Object.keys(map_or_text)) {\n","                result[item] = eval_functions(map_or_text[item]);\n","            }\n","            return result;\n","        }\n","    }\n","\n","    return map_or_text;\n","}\n","\n","</` + 'script>');"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"iRqIusXhEsUJ","cellView":"form","executionInfo":{"status":"ok","timestamp":1625764428464,"user_tz":-330,"elapsed":487,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["#@markdown\n","import pandas as pd\n","import numpy as np\n","import requests\n","import time\n","import os\n","from tqdm import tqdm\n","from pyarrow import feather\n","\n","\n","def get_recent_changes(N):\n","    S = requests.Session()\n","\n","    t = tqdm(total=N, position=0, leave=True)\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"format\": \"json\",\n","        \"rcprop\": \"title|ids|sizes|flags|user|userid|timestamp\",\n","        \"rcshow\": \"!bot|!anon|!minor\",\n","        \"rctype\": \"edit\",\n","        \"rcnamespace\": \"0\",\n","        \"list\": \"recentchanges\",\n","        \"action\": \"query\",\n","        \"rclimit\": \"500\",\n","    }\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","    all_rc = RECENTCHANGES\n","\n","    i = 500\n","    t.update(500)\n","    while i <= N:\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        RECENTCHANGES = DATA[\"query\"][\"recentchanges\"]\n","        all_rc.extend(RECENTCHANGES)\n","        i = i + 500\n","        t.update(500)\n","\n","    if len(all_rc) > N:\n","        all_rc = all_rc[:N]\n","\n","    return all_rc\n","\n","\n","def get_sample_of_users(edit_lookback, outfile=None):\n","    \"\"\"Get a sample of recently active users by pulling the most recent N edits\n","    Note that this will be biased towards highly active users.\n","    Args:\n","        edit_lookback: The number of edits to go back.\n","        outfile: Pickle file path to write the user list to\n","    Returns:\n","        Dataframe with user and user id columns\n","    \"\"\"\n","    df = get_recent_changes(edit_lookback)\n","\n","    # Drop missing userid entries\n","    df = pd.DataFrame(df).dropna(subset=[\"userid\"])\n","\n","    print(\"Earliest timestamp: {}\".format(df.timestamp.min()))\n","    print(\"Latest timestamp: {}\".format(df.timestamp.max()))\n","    print(\"Number of distinct users: {}\".format(len(df.user.unique())))\n","    print(\n","        \"Mean number of edits per user in timeframe: %.2f\"\n","        % (len(df) / len(df.user.unique()))\n","    )\n","    print(\"Number of distinct pages edited: {}\".format(len(df.pageid.unique())))\n","    print(\n","        \"Mean number of edits per page in timeframe: %.2f\"\n","        % (len(df) / len(df.pageid.unique()))\n","    )\n","\n","    # Deduplicate to get\n","    sampled_users = df.loc[:, [\"user\", \"userid\"]].drop_duplicates()\n","\n","    # Remove RFD\n","    sampled_users = sampled_users[np.invert(sampled_users.user == \"RFD\")]\n","    sampled_users = sampled_users.reset_index(drop=True)\n","\n","    if outfile:\n","        sampled_users.to_csv(outfile, index=False)\n","\n","    return sampled_users\n","\n","\n","def get_edit_history(\n","    userid=None, user=None, latest_timestamp=None, earliest_timestamp=None, limit=None):\n","    \"\"\"For a particular user, pull their whole history of edits.\n","    Args:\n","        param1 (int): The first parameter.\n","        param2 (str): The second parameter.\n","    Returns:\n","        bool: The return value. True for success, False otherwise.\n","    \"\"\"\n","\n","    S = requests.Session()\n","    S.headers.update(\n","        {\"User-Agent\": \"WikiRecs (danielrsaunders@gmail.com) One-time pull\"}\n","    )\n","\n","    URL = \"https://en.wikipedia.org/w/api.php\"\n","\n","    PARAMS = {\n","        \"action\": \"query\",\n","        \"format\": \"json\",\n","        \"ucnamespace\": \"0\",\n","        \"list\": \"usercontribs\",\n","        \"ucuserids\": userid,\n","        \"ucprop\": \"title|ids|sizediff|flags|comment|timestamp\",\n","        \"ucshow=\": \"!minor|!new\",\n","    }\n","    if latest_timestamp is not None:\n","        PARAMS[\"ucstart\"] = latest_timestamp\n","    if earliest_timestamp is not None:\n","        PARAMS[\"ucend\"] = earliest_timestamp\n","    if user is not None:\n","        PARAMS[\"ucuser\"] = user\n","    if userid is not None:\n","        PARAMS[\"ucuserid\"] = userid\n","\n","    PARAMS[\"uclimit\"] = 500\n","\n","    R = S.get(url=URL, params=PARAMS)\n","    DATA = R.json()\n","\n","    if \"query\" not in DATA:\n","        print(DATA)\n","        raise ValueError\n","\n","    USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","    all_ucs = USERCONTRIBS\n","    i = 500\n","    while i < 100000:\n","        if \"continue\" not in DATA:\n","            break\n","        last_continue = DATA[\"continue\"]\n","        PARAMS.update(last_continue)\n","        R = S.get(url=URL, params=PARAMS)\n","        DATA = R.json()\n","        USERCONTRIBS = DATA[\"query\"][\"usercontribs\"]\n","        all_ucs.extend(USERCONTRIBS)\n","        i = i + 500\n","\n","    return all_ucs\n","\n","\n","def pull_edit_histories(\n","    sampled_users_file,\n","    edit_histories_file_pattern,\n","    users_per_chunk,\n","    earliest_timestamp,\n","    start=0):\n","    histories = []\n","    cols = [\"userid\", \"user\", \"pageid\", \"title\", \"timestamp\", \"sizediff\"]\n","    sampled_users = pd.read_csv(sampled_users_file)\n","    sampled_users.loc[:, \"userid\"].astype(int)\n","\n","    sampled_users = sampled_users.reset_index()\n","\n","    # Iterate through all the users in the list\n","    for i, (user, userid) in tqdm(\n","        iterable=enumerate(\n","            zip(sampled_users[\"user\"][start:], sampled_users[\"userid\"][start:]),\n","            start=start),\n","        total=len(sampled_users)): \n","\n","        # Get the history of edits for this userid\n","        thehistory = get_edit_history(\n","            userid=int(userid), earliest_timestamp=earliest_timestamp\n","        )\n","\n","        # If no edits, skip\n","        if len(thehistory) == 0:\n","            continue\n","\n","        thehistory = pd.DataFrame(thehistory)\n","\n","        # Remove edits using automated tools by looking for the word \"using\" in the comments\n","        try:\n","            thehistory = thehistory[\n","                np.invert(thehistory.comment.astype(str).str.contains(\"using\"))\n","            ]\n","        except AttributeError:\n","            continue\n","\n","        if len(thehistory) == 0:\n","            continue\n","\n","        histories.append(thehistory.loc[:, cols])\n","\n","        # if np.mod(i, 50) == 0:\n","        #     print(\n","        #         \"Most recent: {}/{} {} ({}) has {} edits\".format(\n","        #             i, len(sampled_users), user, int(userid), len(thehistory)\n","        #         )\n","        #     )\n","\n","        # Every x users save it out, for the sake of ram limitations\n","        if np.mod(i, users_per_chunk) == 0:\n","            feather.write_feather(\n","                pd.concat(histories), edit_histories_file_pattern.format(i)\n","            )\n","\n","            histories = []\n","      \n","    # Get the last few users that don't make up a full chunk\n","    feather.write_feather(pd.concat(histories), edit_histories_file_pattern.format(i))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vNLJxSLB2m8","outputId":"5d885a35-a0c1-40ae-e64e-5dbacaacf051"},"source":["pull_edit_histories(\n","    config['outfile'],\n","    os.path.join(config['file_save_path'],config['edit_histories_file_pattern']),\n","    config['users_per_chunk'],\n","    config['earliest_timestamp'],\n","    start=15000,\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  9%|â–‰         | 5112/54339 [19:31<3:42:59,  3.68it/s]"],"name":"stderr"}]}]}