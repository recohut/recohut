"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4808],{3905:function(e,t,r){r.d(t,{Zo:function(){return d},kt:function(){return p}});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var c=n.createContext({}),l=function(e){var t=n.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},d=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),m=l(r),p=a,f=m["".concat(c,".").concat(p)]||m[p]||u[p]||o;return r?n.createElement(f,s(s({ref:t},d),{},{components:r})):n.createElement(f,s({ref:t},d))}));function p(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,s=new Array(o);s[0]=m;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:a,s[1]=i;for(var l=2;l<o;l++)s[l]=r[l];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},80744:function(e,t,r){r.r(t),r.d(t,{assets:function(){return d},contentTitle:function(){return c},default:function(){return p},frontMatter:function(){return i},metadata:function(){return l},toc:function(){return u}});var n=r(87462),a=r(63366),o=(r(67294),r(3905)),s=["components"],i={},c="BST",l={unversionedId:"models/bst",id:"models/bst",title:"BST",description:"It stands for Behavior Sequence Transformer.",source:"@site/docs/models/bst.mdx",sourceDirName:"models",slug:"/models/bst",permalink:"/ai/docs/models/bst",editUrl:"https://github.com/sparsh-ai/ai/docs/models/bst.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"BPR",permalink:"/ai/docs/models/bpr"},next:{title:"CASER",permalink:"/ai/docs/models/caser"}},d={},u=[{value:"References",id:"references",level:2}],m={toc:u};function p(e){var t=e.components,r=(0,a.Z)(e,s);return(0,o.kt)("wrapper",(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"bst"},"BST"),(0,o.kt)("p",null,"It stands for Behavior Sequence Transformer."),(0,o.kt)("p",null,"Deep learning based methods have been widely used in industrial recommendation systems (RSs). Previous works adopt an Embedding & MLP paradigm: raw features are embedded into low-dimensional vectors, which are then fed onto MLP for final recommendations. However, most of these works just concatenate different features, ignoring the sequential nature of users' behaviors. BST model uses the powerful Transformer model to capture the sequential signals underlying users' behavior sequences for recommendation."),(0,o.kt)("p",null,"Inspired by the great success of the Transformer for machine translation task in natural language processing (NLP) , this model applies the self-attention mechanism to learn a better representation for each item in a user\u2019s behavior sequence by considering the sequential information in embedding stage, and then feed them into MLPs to predict users\u2019 responses to candidate items. The key advantage of the Transformer is that it can better capture the dependency among words in sentences by the self-attention mechanism, and intuitively speaking, the \u201cdependency\u201d among items in users\u2019 behavior sequences can also be extracted by the Transformer."),(0,o.kt)("p",null,(0,o.kt)("center",null,(0,o.kt)("img",{src:"https://github.com/recohut/transformer-rec/raw/132decd8b7004cd43163b71d70a501bc150fd5f2/docs/_images/C220331_1.png"}))),(0,o.kt)("h2",{id:"references"},"References"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1905.06874"},"Qiwei Chen, Huan Zhao, Wei Li, Pipei Huang, Wenwu Ou. 2019. arXiv.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/D-Roberts/transformer-recommender"},"D-Roberts (2021) Transformer based recommendation systems [Source code].")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/shenweichen/DeepCTR"},"shenweichen (2021) Easy-to-use,Modular and Extendible package of deep-learning based CTR models [Source code]")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/jiwidi/Behavior-Sequence-Transformer-Pytorch"},"jiwidi (2021) Behavior-Sequence-Transformer-Pytorch [Source code].")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/nihalsangeeth/behaviour-seq-transformer"},"nihalsangeeth (2021) Behaviour Sequence Transformers [Source code].")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://keras.io/examples/structured_data/movielens_recommendations_transformers"},"Khalid Salama (2020) A Transformer-based recommendation system [Source code].")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://deepctr-doc.readthedocs.io/en/latest/deepctr.models.sequence.bst.html"},"BST DeepCTR library")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://github.com/PaddlePaddle/PaddleRec/tree/release/1.8.5/models/rank/BST/"},"https://github.com/PaddlePaddle/PaddleRec/tree/release/1.8.5/models/rank/BST/"))))}p.isMDXComponent=!0}}]);