{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms1RfbNVeRIb"
      },
      "outputs": [],
      "source": [
        "# default_exp datasets.bases.common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAzceUi3eRIk"
      },
      "source": [
        "# Base dataset\n",
        "> Base class for dataset module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgdIIOUZeRIq"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDNCoBdAeRIs"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "from typing import List, Optional, Callable, Union, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from abc import *\n",
        "from pathlib import Path\n",
        "import os\n",
        "import os.path as osp\n",
        "from collections.abc import Sequence\n",
        "import sys\n",
        "import tempfile\n",
        "import shutil\n",
        "import pickle\n",
        "import time\n",
        "import csv\n",
        "import math\n",
        "import operator\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import datetime\n",
        "from datetime import date, timezone, timedelta\n",
        "from pandas import Timedelta\n",
        "\n",
        "import torch\n",
        "\n",
        "from recohut.utils.common_utils import download_url, extract_zip, extract_gz, makedirs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ggqs8PKeRIv"
      },
      "outputs": [],
      "source": [
        "#exporti\n",
        "def to_list(value: Any) -> Sequence:\n",
        "    if isinstance(value, Sequence) and not isinstance(value, str):\n",
        "        return value\n",
        "    else:\n",
        "        return [value]\n",
        "\n",
        "def files_exist(files: List[str]) -> bool:\n",
        "    # NOTE: We return `False` in case `files` is empty, leading to a\n",
        "    # re-processing of files on every instantiation.\n",
        "    return len(files) != 0 and all([osp.exists(f) for f in files])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZQYhfvBeRIx"
      },
      "outputs": [],
      "source": [
        "#exporti\n",
        "class Dataset:\n",
        "    \"\"\"Dataset base class\n",
        "    \"\"\"\n",
        "    @property\n",
        "    def raw_file_names(self) -> Union[str, List[str], Tuple]:\n",
        "        r\"\"\"The name of the files in the :obj:`self.raw_dir` folder that must\n",
        "        be present in order to skip downloading.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> Union[str, List[str], Tuple]:\n",
        "        r\"\"\"The name of the files in the :obj:`self.processed_dir` folder that\n",
        "        must be present in order to skip processing.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def download(self):\n",
        "        r\"\"\"Downloads the dataset to the :obj:`self.raw_dir` folder.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def process(self):\n",
        "        r\"\"\"Processes the dataset to the :obj:`self.processed_dir` folder.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __init__(self, root=None):\n",
        "        self.root = root\n",
        "\n",
        "        if 'download' in self.__class__.__dict__:\n",
        "            self._download()\n",
        "\n",
        "        # if 'process' in self.__class__.__dict__:\n",
        "        #     self._process()\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self) -> str:\n",
        "        return osp.join(self.root, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_dir(self) -> str:\n",
        "        return osp.join(self.root, 'processed')\n",
        "\n",
        "    @property\n",
        "    def raw_paths(self) -> List[str]:\n",
        "        r\"\"\"The absolute filepaths that must be present in order to skip\n",
        "        downloading.\"\"\"\n",
        "        files = to_list(self.raw_file_names)\n",
        "        return [osp.join(self.raw_dir, f) for f in files]\n",
        "\n",
        "    @property\n",
        "    def processed_paths(self) -> List[str]:\n",
        "        r\"\"\"The absolute filepaths that must be present in order to skip\n",
        "        processing.\"\"\"\n",
        "        files = to_list(self.processed_file_names)\n",
        "        return [osp.join(self.processed_dir, f) for f in files]\n",
        "\n",
        "    def _download(self):\n",
        "        if files_exist(self.raw_paths):  # pragma: no cover\n",
        "            return\n",
        "\n",
        "        makedirs(self.raw_dir)\n",
        "        self.download()\n",
        "\n",
        "    def _process(self):\n",
        "        if files_exist(self.processed_paths):  # pragma: no cover\n",
        "            return\n",
        "\n",
        "        print('Processing...', file=sys.stderr)\n",
        "\n",
        "        makedirs(self.processed_dir)\n",
        "        self.process()\n",
        "\n",
        "        print('Done!', file=sys.stderr)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        arg_repr = str(len(self)) if len(self) > 1 else ''\n",
        "        return f'{self.__class__.__name__}({arg_repr})'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "datasets.bases.common.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}